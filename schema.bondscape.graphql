# This file was generated. Do not edit manually.

schema {
    query: query_root
    mutation: mutation_root
    subscription: subscription_root
}

"whether this query should be cached (Hasura Cloud only)"
directive @cached(
    "refresh the cache entry"
    refresh: Boolean! = false,
    "measured in seconds"
    ttl: Int! = 60
) on QUERY

"columns and relationships of \"bond_shared_contacts\""
type bond_shared_contacts {
    "An object relationship"
    bond: bonds!
    bond_id: String!
    "An object relationship"
    contact: user_contacts!
    contact_id: String!
    id: String!
}

"aggregated selection of \"bond_shared_contacts\""
type bond_shared_contacts_aggregate {
    aggregate: bond_shared_contacts_aggregate_fields
    nodes: [bond_shared_contacts!]!
}

"aggregate fields of \"bond_shared_contacts\""
type bond_shared_contacts_aggregate_fields {
    count(columns: [bond_shared_contacts_select_column!], distinct: Boolean): Int!
    max: bond_shared_contacts_max_fields
    min: bond_shared_contacts_min_fields
}

"aggregate max on columns"
type bond_shared_contacts_max_fields {
    bond_id: String
    contact_id: String
    id: String
}

"aggregate min on columns"
type bond_shared_contacts_min_fields {
    bond_id: String
    contact_id: String
    id: String
}

"response of any mutation on the table \"bond_shared_contacts\""
type bond_shared_contacts_mutation_response {
    "number of rows affected by the mutation"
    affected_rows: Int!
    "data from the rows affected by the mutation"
    returning: [bond_shared_contacts!]!
}

"columns and relationships of \"bonds\""
type bonds {
    counterparty: profile
    counterparty_address: String!
    counterparty_tx_hash: String
    creation_time: timestamptz!
    creator: profile
    creator_address: String!
    creator_tx_hash: String!
    "An object relationship"
    event: events
    event_id: String
    id: String!
    "An object relationship"
    photo_hash: images_hashes
    photo_url: String
    "An array relationship"
    shared_contacts(
        "distinct select on columns"
        distinct_on: [bond_shared_contacts_select_column!],
        "limit the number of rows returned"
        limit: Int,
        "skip the first n rows. Use only with order_by"
        offset: Int,
        "sort the rows by one or more columns"
        order_by: [bond_shared_contacts_order_by!],
        "filter the rows returned"
        where: bond_shared_contacts_bool_exp
    ): [bond_shared_contacts!]!
    "An aggregate relationship"
    shared_contacts_aggregate(
        "distinct select on columns"
        distinct_on: [bond_shared_contacts_select_column!],
        "limit the number of rows returned"
        limit: Int,
        "skip the first n rows. Use only with order_by"
        offset: Int,
        "sort the rows by one or more columns"
        order_by: [bond_shared_contacts_order_by!],
        "filter the rows returned"
        where: bond_shared_contacts_bool_exp
    ): bond_shared_contacts_aggregate!
    status: bond_status!
}

"aggregated selection of \"bonds\""
type bonds_aggregate {
    aggregate: bonds_aggregate_fields
    nodes: [bonds!]!
}

"aggregate fields of \"bonds\""
type bonds_aggregate_fields {
    count(columns: [bonds_select_column!], distinct: Boolean): Int!
    max: bonds_max_fields
    min: bonds_min_fields
}

"aggregate max on columns"
type bonds_max_fields {
    counterparty_address: String
    counterparty_tx_hash: String
    creation_time: timestamptz
    creator_address: String
    creator_tx_hash: String
    event_id: String
    id: String
    photo_url: String
    status: bond_status
}

"aggregate min on columns"
type bonds_min_fields {
    counterparty_address: String
    counterparty_tx_hash: String
    creation_time: timestamptz
    creator_address: String
    creator_tx_hash: String
    event_id: String
    id: String
    photo_url: String
    status: bond_status
}

"response of any mutation on the table \"bonds\""
type bonds_mutation_response {
    "number of rows affected by the mutation"
    affected_rows: Int!
    "data from the rows affected by the mutation"
    returning: [bonds!]!
}

"columns and relationships of \"event_categories\""
type event_categories {
    category_id: Int!
    event_id: String!
    id: Int!
}

"aggregated selection of \"event_categories\""
type event_categories_aggregate {
    aggregate: event_categories_aggregate_fields
    nodes: [event_categories!]!
}

"aggregate fields of \"event_categories\""
type event_categories_aggregate_fields {
    avg: event_categories_avg_fields
    count(columns: [event_categories_select_column!], distinct: Boolean): Int!
    max: event_categories_max_fields
    min: event_categories_min_fields
    stddev: event_categories_stddev_fields
    stddev_pop: event_categories_stddev_pop_fields
    stddev_samp: event_categories_stddev_samp_fields
    sum: event_categories_sum_fields
    var_pop: event_categories_var_pop_fields
    var_samp: event_categories_var_samp_fields
    variance: event_categories_variance_fields
}

"aggregate avg on columns"
type event_categories_avg_fields {
    category_id: Float
    id: Float
}

"aggregate max on columns"
type event_categories_max_fields {
    category_id: Int
    event_id: String
    id: Int
}

"aggregate min on columns"
type event_categories_min_fields {
    category_id: Int
    event_id: String
    id: Int
}

"response of any mutation on the table \"event_categories\""
type event_categories_mutation_response {
    "number of rows affected by the mutation"
    affected_rows: Int!
    "data from the rows affected by the mutation"
    returning: [event_categories!]!
}

"aggregate stddev on columns"
type event_categories_stddev_fields {
    category_id: Float
    id: Float
}

"aggregate stddev_pop on columns"
type event_categories_stddev_pop_fields {
    category_id: Float
    id: Float
}

"aggregate stddev_samp on columns"
type event_categories_stddev_samp_fields {
    category_id: Float
    id: Float
}

"aggregate sum on columns"
type event_categories_sum_fields {
    category_id: Int
    id: Int
}

"aggregate var_pop on columns"
type event_categories_var_pop_fields {
    category_id: Float
    id: Float
}

"aggregate var_samp on columns"
type event_categories_var_samp_fields {
    category_id: Float
    id: Float
}

"aggregate variance on columns"
type event_categories_variance_fields {
    category_id: Float
    id: Float
}

"columns and relationships of \"event_likes\""
type event_likes {
    creation_time: timestamptz!
    "An object relationship"
    event: events!
    event_id: String!
    liker: profile
    liker_address: String!
}

"aggregated selection of \"event_likes\""
type event_likes_aggregate {
    aggregate: event_likes_aggregate_fields
    nodes: [event_likes!]!
}

"aggregate fields of \"event_likes\""
type event_likes_aggregate_fields {
    count(columns: [event_likes_select_column!], distinct: Boolean): Int!
    max: event_likes_max_fields
    min: event_likes_min_fields
}

"aggregate max on columns"
type event_likes_max_fields {
    creation_time: timestamptz
    event_id: String
    liker_address: String
}

"aggregate min on columns"
type event_likes_min_fields {
    creation_time: timestamptz
    event_id: String
    liker_address: String
}

"response of any mutation on the table \"event_likes\""
type event_likes_mutation_response {
    "number of rows affected by the mutation"
    affected_rows: Int!
    "data from the rows affected by the mutation"
    returning: [event_likes!]!
}

"columns and relationships of \"event_organizers\""
type event_organizers {
    "An object relationship"
    event: events!
    event_id: String!
    id: Int!
    organizer: profile
    organizer_address: String!
}

"aggregated selection of \"event_organizers\""
type event_organizers_aggregate {
    aggregate: event_organizers_aggregate_fields
    nodes: [event_organizers!]!
}

"aggregate fields of \"event_organizers\""
type event_organizers_aggregate_fields {
    avg: event_organizers_avg_fields
    count(columns: [event_organizers_select_column!], distinct: Boolean): Int!
    max: event_organizers_max_fields
    min: event_organizers_min_fields
    stddev: event_organizers_stddev_fields
    stddev_pop: event_organizers_stddev_pop_fields
    stddev_samp: event_organizers_stddev_samp_fields
    sum: event_organizers_sum_fields
    var_pop: event_organizers_var_pop_fields
    var_samp: event_organizers_var_samp_fields
    variance: event_organizers_variance_fields
}

"aggregate avg on columns"
type event_organizers_avg_fields {
    id: Float
}

"aggregate max on columns"
type event_organizers_max_fields {
    event_id: String
    id: Int
    organizer_address: String
}

"aggregate min on columns"
type event_organizers_min_fields {
    event_id: String
    id: Int
    organizer_address: String
}

"response of any mutation on the table \"event_organizers\""
type event_organizers_mutation_response {
    "number of rows affected by the mutation"
    affected_rows: Int!
    "data from the rows affected by the mutation"
    returning: [event_organizers!]!
}

"aggregate stddev on columns"
type event_organizers_stddev_fields {
    id: Float
}

"aggregate stddev_pop on columns"
type event_organizers_stddev_pop_fields {
    id: Float
}

"aggregate stddev_samp on columns"
type event_organizers_stddev_samp_fields {
    id: Float
}

"aggregate sum on columns"
type event_organizers_sum_fields {
    id: Int
}

"aggregate var_pop on columns"
type event_organizers_var_pop_fields {
    id: Float
}

"aggregate var_samp on columns"
type event_organizers_var_samp_fields {
    id: Float
}

"aggregate variance on columns"
type event_organizers_variance_fields {
    id: Float
}

"columns and relationships of \"event_participations\""
type event_participations {
    "An object relationship"
    event: events!
    event_id: String!
    id: Int!
    participant_address: String!
    participation_end_time: timestamptz
    participation_start_time: timestamptz!
}

"aggregated selection of \"event_participations\""
type event_participations_aggregate {
    aggregate: event_participations_aggregate_fields
    nodes: [event_participations!]!
}

"aggregate fields of \"event_participations\""
type event_participations_aggregate_fields {
    avg: event_participations_avg_fields
    count(columns: [event_participations_select_column!], distinct: Boolean): Int!
    max: event_participations_max_fields
    min: event_participations_min_fields
    stddev: event_participations_stddev_fields
    stddev_pop: event_participations_stddev_pop_fields
    stddev_samp: event_participations_stddev_samp_fields
    sum: event_participations_sum_fields
    var_pop: event_participations_var_pop_fields
    var_samp: event_participations_var_samp_fields
    variance: event_participations_variance_fields
}

"aggregate avg on columns"
type event_participations_avg_fields {
    id: Float
}

"aggregate max on columns"
type event_participations_max_fields {
    event_id: String
    id: Int
    participant_address: String
    participation_end_time: timestamptz
    participation_start_time: timestamptz
}

"aggregate min on columns"
type event_participations_min_fields {
    event_id: String
    id: Int
    participant_address: String
    participation_end_time: timestamptz
    participation_start_time: timestamptz
}

"response of any mutation on the table \"event_participations\""
type event_participations_mutation_response {
    "number of rows affected by the mutation"
    affected_rows: Int!
    "data from the rows affected by the mutation"
    returning: [event_participations!]!
}

"aggregate stddev on columns"
type event_participations_stddev_fields {
    id: Float
}

"aggregate stddev_pop on columns"
type event_participations_stddev_pop_fields {
    id: Float
}

"aggregate stddev_samp on columns"
type event_participations_stddev_samp_fields {
    id: Float
}

"aggregate sum on columns"
type event_participations_sum_fields {
    id: Int
}

"aggregate var_pop on columns"
type event_participations_var_pop_fields {
    id: Float
}

"aggregate var_samp on columns"
type event_participations_var_samp_fields {
    id: Float
}

"aggregate variance on columns"
type event_participations_variance_fields {
    id: Float
}

"columns and relationships of \"event_tags\""
type event_tags {
    event_count: bigint
    tag: String
}

"aggregated selection of \"event_tags\""
type event_tags_aggregate {
    aggregate: event_tags_aggregate_fields
    nodes: [event_tags!]!
}

"aggregate fields of \"event_tags\""
type event_tags_aggregate_fields {
    avg: event_tags_avg_fields
    count(columns: [event_tags_select_column!], distinct: Boolean): Int!
    max: event_tags_max_fields
    min: event_tags_min_fields
    stddev: event_tags_stddev_fields
    stddev_pop: event_tags_stddev_pop_fields
    stddev_samp: event_tags_stddev_samp_fields
    sum: event_tags_sum_fields
    var_pop: event_tags_var_pop_fields
    var_samp: event_tags_var_samp_fields
    variance: event_tags_variance_fields
}

"aggregate avg on columns"
type event_tags_avg_fields {
    event_count: Float
}

"aggregate max on columns"
type event_tags_max_fields {
    event_count: bigint
    tag: String
}

"aggregate min on columns"
type event_tags_min_fields {
    event_count: bigint
    tag: String
}

"aggregate stddev on columns"
type event_tags_stddev_fields {
    event_count: Float
}

"aggregate stddev_pop on columns"
type event_tags_stddev_pop_fields {
    event_count: Float
}

"aggregate stddev_samp on columns"
type event_tags_stddev_samp_fields {
    event_count: Float
}

"aggregate sum on columns"
type event_tags_sum_fields {
    event_count: bigint
}

"aggregate var_pop on columns"
type event_tags_var_pop_fields {
    event_count: Float
}

"aggregate var_samp on columns"
type event_tags_var_samp_fields {
    event_count: Float
}

"aggregate variance on columns"
type event_tags_variance_fields {
    event_count: Float
}

"columns and relationships of \"events\""
type events {
    "An array relationship"
    bonds(
        "distinct select on columns"
        distinct_on: [bonds_select_column!],
        "limit the number of rows returned"
        limit: Int,
        "skip the first n rows. Use only with order_by"
        offset: Int,
        "sort the rows by one or more columns"
        order_by: [bonds_order_by!],
        "filter the rows returned"
        where: bonds_bool_exp
    ): [bonds!]!
    "An aggregate relationship"
    bonds_aggregate(
        "distinct select on columns"
        distinct_on: [bonds_select_column!],
        "limit the number of rows returned"
        limit: Int,
        "skip the first n rows. Use only with order_by"
        offset: Int,
        "sort the rows by one or more columns"
        order_by: [bonds_order_by!],
        "filter the rows returned"
        where: bonds_bool_exp
    ): bonds_aggregate!
    "An object relationship"
    cover_picture_hash: images_hashes
    cover_picture_url: String
    description: String!
    details_link: String
    end_date: timestamptz
    google_place_id: String
    id: String!
    "A computed field, executes function \"is_user_participating_to_event\""
    is_user_participating: Boolean
    join_code: String!
    join_link: String
    "An array relationship"
    likes(
        "distinct select on columns"
        distinct_on: [event_likes_select_column!],
        "limit the number of rows returned"
        limit: Int,
        "skip the first n rows. Use only with order_by"
        offset: Int,
        "sort the rows by one or more columns"
        order_by: [event_likes_order_by!],
        "filter the rows returned"
        where: event_likes_bool_exp
    ): [event_likes!]!
    "An aggregate relationship"
    likes_aggregate(
        "distinct select on columns"
        distinct_on: [event_likes_select_column!],
        "limit the number of rows returned"
        limit: Int,
        "skip the first n rows. Use only with order_by"
        offset: Int,
        "sort the rows by one or more columns"
        order_by: [event_likes_order_by!],
        "filter the rows returned"
        where: event_likes_bool_exp
    ): event_likes_aggregate!
    "A computed field, executes function \"event_likes_count\""
    likes_count: bigint
    location_administrative_area_level_1: String
    location_administrative_area_level_2: String
    location_administrative_area_level_3: String
    location_coordinates: geography
    location_country: String
    location_formatted_address: String
    location_locality: String
    "An array relationship"
    memories(
        "distinct select on columns"
        distinct_on: [memories_select_column!],
        "limit the number of rows returned"
        limit: Int,
        "skip the first n rows. Use only with order_by"
        offset: Int,
        "sort the rows by one or more columns"
        order_by: [memories_order_by!],
        "filter the rows returned"
        where: memories_bool_exp
    ): [memories!]!
    "An aggregate relationship"
    memories_aggregate(
        "distinct select on columns"
        distinct_on: [memories_select_column!],
        "limit the number of rows returned"
        limit: Int,
        "skip the first n rows. Use only with order_by"
        offset: Int,
        "sort the rows by one or more columns"
        order_by: [memories_order_by!],
        "filter the rows returned"
        where: memories_bool_exp
    ): memories_aggregate!
    name: String!
    "An array relationship"
    organizers(
        "distinct select on columns"
        distinct_on: [event_organizers_select_column!],
        "limit the number of rows returned"
        limit: Int,
        "skip the first n rows. Use only with order_by"
        offset: Int,
        "sort the rows by one or more columns"
        order_by: [event_organizers_order_by!],
        "filter the rows returned"
        where: event_organizers_bool_exp
    ): [event_organizers!]!
    "An aggregate relationship"
    organizers_aggregate(
        "distinct select on columns"
        distinct_on: [event_organizers_select_column!],
        "limit the number of rows returned"
        limit: Int,
        "skip the first n rows. Use only with order_by"
        offset: Int,
        "sort the rows by one or more columns"
        order_by: [event_organizers_order_by!],
        "filter the rows returned"
        where: event_organizers_bool_exp
    ): event_organizers_aggregate!
    "A computed field, executes function \"event_participants_count\""
    participants_count: bigint
    "An array relationship"
    participations(
        "distinct select on columns"
        distinct_on: [event_participations_select_column!],
        "limit the number of rows returned"
        limit: Int,
        "skip the first n rows. Use only with order_by"
        offset: Int,
        "sort the rows by one or more columns"
        order_by: [event_participations_order_by!],
        "filter the rows returned"
        where: event_participations_bool_exp
    ): [event_participations!]!
    "An aggregate relationship"
    participations_aggregate(
        "distinct select on columns"
        distinct_on: [event_participations_select_column!],
        "limit the number of rows returned"
        limit: Int,
        "skip the first n rows. Use only with order_by"
        offset: Int,
        "sort the rows by one or more columns"
        order_by: [event_participations_order_by!],
        "filter the rows returned"
        where: event_participations_bool_exp
    ): event_participations_aggregate!
    start_date: timestamptz
    tags(
        "JSON select path"
        path: String
    ): jsonb!
    website: String
}

"aggregated selection of \"events\""
type events_aggregate {
    aggregate: events_aggregate_fields
    nodes: [events!]!
}

"aggregate fields of \"events\""
type events_aggregate_fields {
    count(columns: [events_select_column!], distinct: Boolean): Int!
    max: events_max_fields
    min: events_min_fields
}

"columns and relationships of \"events_categories\""
type events_categories {
    id: Int!
    name: String!
}

"aggregated selection of \"events_categories\""
type events_categories_aggregate {
    aggregate: events_categories_aggregate_fields
    nodes: [events_categories!]!
}

"aggregate fields of \"events_categories\""
type events_categories_aggregate_fields {
    avg: events_categories_avg_fields
    count(columns: [events_categories_select_column!], distinct: Boolean): Int!
    max: events_categories_max_fields
    min: events_categories_min_fields
    stddev: events_categories_stddev_fields
    stddev_pop: events_categories_stddev_pop_fields
    stddev_samp: events_categories_stddev_samp_fields
    sum: events_categories_sum_fields
    var_pop: events_categories_var_pop_fields
    var_samp: events_categories_var_samp_fields
    variance: events_categories_variance_fields
}

"aggregate avg on columns"
type events_categories_avg_fields {
    id: Float
}

"aggregate max on columns"
type events_categories_max_fields {
    id: Int
    name: String
}

"aggregate min on columns"
type events_categories_min_fields {
    id: Int
    name: String
}

"response of any mutation on the table \"events_categories\""
type events_categories_mutation_response {
    "number of rows affected by the mutation"
    affected_rows: Int!
    "data from the rows affected by the mutation"
    returning: [events_categories!]!
}

"aggregate stddev on columns"
type events_categories_stddev_fields {
    id: Float
}

"aggregate stddev_pop on columns"
type events_categories_stddev_pop_fields {
    id: Float
}

"aggregate stddev_samp on columns"
type events_categories_stddev_samp_fields {
    id: Float
}

"aggregate sum on columns"
type events_categories_sum_fields {
    id: Int
}

"aggregate var_pop on columns"
type events_categories_var_pop_fields {
    id: Float
}

"aggregate var_samp on columns"
type events_categories_var_samp_fields {
    id: Float
}

"aggregate variance on columns"
type events_categories_variance_fields {
    id: Float
}

"aggregate max on columns"
type events_max_fields {
    cover_picture_url: String
    description: String
    details_link: String
    end_date: timestamptz
    google_place_id: String
    id: String
    join_code: String
    join_link: String
    location_administrative_area_level_1: String
    location_administrative_area_level_2: String
    location_administrative_area_level_3: String
    location_country: String
    location_formatted_address: String
    location_locality: String
    name: String
    start_date: timestamptz
    website: String
}

"aggregate min on columns"
type events_min_fields {
    cover_picture_url: String
    description: String
    details_link: String
    end_date: timestamptz
    google_place_id: String
    id: String
    join_code: String
    join_link: String
    location_administrative_area_level_1: String
    location_administrative_area_level_2: String
    location_administrative_area_level_3: String
    location_country: String
    location_formatted_address: String
    location_locality: String
    name: String
    start_date: timestamptz
    website: String
}

"response of any mutation on the table \"events\""
type events_mutation_response {
    "number of rows affected by the mutation"
    affected_rows: Int!
    "data from the rows affected by the mutation"
    returning: [events!]!
}

"columns and relationships of \"images_hashes\""
type images_hashes {
    hash: String!
    image_url: String!
}

"aggregated selection of \"images_hashes\""
type images_hashes_aggregate {
    aggregate: images_hashes_aggregate_fields
    nodes: [images_hashes!]!
}

"aggregate fields of \"images_hashes\""
type images_hashes_aggregate_fields {
    count(columns: [images_hashes_select_column!], distinct: Boolean): Int!
    max: images_hashes_max_fields
    min: images_hashes_min_fields
}

"aggregate max on columns"
type images_hashes_max_fields {
    hash: String
    image_url: String
}

"aggregate min on columns"
type images_hashes_min_fields {
    hash: String
    image_url: String
}

"response of any mutation on the table \"images_hashes\""
type images_hashes_mutation_response {
    "number of rows affected by the mutation"
    affected_rows: Int!
    "data from the rows affected by the mutation"
    returning: [images_hashes!]!
}

"columns and relationships of \"memories\""
type memories {
    creation_time: timestamptz!
    creator: profile
    creator_address: String!
    details_link: String
    "An object relationship"
    event: events!
    event_id: String!
    id: String!
    "An object relationship"
    image_hash: images_hashes
    image_url: String!
    "An array relationship"
    likes(
        "distinct select on columns"
        distinct_on: [memory_likes_select_column!],
        "limit the number of rows returned"
        limit: Int,
        "skip the first n rows. Use only with order_by"
        offset: Int,
        "sort the rows by one or more columns"
        order_by: [memory_likes_order_by!],
        "filter the rows returned"
        where: memory_likes_bool_exp
    ): [memory_likes!]!
    "An aggregate relationship"
    likes_aggregate(
        "distinct select on columns"
        distinct_on: [memory_likes_select_column!],
        "limit the number of rows returned"
        limit: Int,
        "skip the first n rows. Use only with order_by"
        offset: Int,
        "sort the rows by one or more columns"
        order_by: [memory_likes_order_by!],
        "filter the rows returned"
        where: memory_likes_bool_exp
    ): memory_likes_aggregate!
    "A computed field, executes function \"memory_likes_count\""
    likes_count: bigint
}

"aggregated selection of \"memories\""
type memories_aggregate {
    aggregate: memories_aggregate_fields
    nodes: [memories!]!
}

"aggregate fields of \"memories\""
type memories_aggregate_fields {
    count(columns: [memories_select_column!], distinct: Boolean): Int!
    max: memories_max_fields
    min: memories_min_fields
}

"aggregate max on columns"
type memories_max_fields {
    creation_time: timestamptz
    creator_address: String
    details_link: String
    event_id: String
    id: String
    image_url: String
}

"aggregate min on columns"
type memories_min_fields {
    creation_time: timestamptz
    creator_address: String
    details_link: String
    event_id: String
    id: String
    image_url: String
}

"response of any mutation on the table \"memories\""
type memories_mutation_response {
    "number of rows affected by the mutation"
    affected_rows: Int!
    "data from the rows affected by the mutation"
    returning: [memories!]!
}

"columns and relationships of \"memory_likes\""
type memory_likes {
    creation_time: timestamptz!
    liker: profile
    liker_address: String!
    "An object relationship"
    memory: memories!
    memory_id: String!
}

"aggregated selection of \"memory_likes\""
type memory_likes_aggregate {
    aggregate: memory_likes_aggregate_fields
    nodes: [memory_likes!]!
}

"aggregate fields of \"memory_likes\""
type memory_likes_aggregate_fields {
    count(columns: [memory_likes_select_column!], distinct: Boolean): Int!
    max: memory_likes_max_fields
    min: memory_likes_min_fields
}

"aggregate max on columns"
type memory_likes_max_fields {
    creation_time: timestamptz
    liker_address: String
    memory_id: String
}

"aggregate min on columns"
type memory_likes_min_fields {
    creation_time: timestamptz
    liker_address: String
    memory_id: String
}

"response of any mutation on the table \"memory_likes\""
type memory_likes_mutation_response {
    "number of rows affected by the mutation"
    affected_rows: Int!
    "data from the rows affected by the mutation"
    returning: [memory_likes!]!
}

"mutation root"
type mutation_root {
    "delete data from the table: \"bond_shared_contacts\""
    delete_bond_shared_contacts(
        "filter the rows which have to be deleted"
        where: bond_shared_contacts_bool_exp!
    ): bond_shared_contacts_mutation_response
    "delete single row from the table: \"bond_shared_contacts\""
    delete_bond_shared_contacts_by_pk(id: String!): bond_shared_contacts
    "delete data from the table: \"bonds\""
    delete_bonds(
        "filter the rows which have to be deleted"
        where: bonds_bool_exp!
    ): bonds_mutation_response
    "delete single row from the table: \"bonds\""
    delete_bonds_by_pk(id: String!): bonds
    "delete data from the table: \"event_categories\""
    delete_event_categories(
        "filter the rows which have to be deleted"
        where: event_categories_bool_exp!
    ): event_categories_mutation_response
    "delete single row from the table: \"event_categories\""
    delete_event_categories_by_pk(id: Int!): event_categories
    "delete data from the table: \"event_likes\""
    delete_event_likes(
        "filter the rows which have to be deleted"
        where: event_likes_bool_exp!
    ): event_likes_mutation_response
    "delete single row from the table: \"event_likes\""
    delete_event_likes_by_pk(event_id: String!, liker_address: String!): event_likes
    "delete data from the table: \"event_organizers\""
    delete_event_organizers(
        "filter the rows which have to be deleted"
        where: event_organizers_bool_exp!
    ): event_organizers_mutation_response
    "delete single row from the table: \"event_organizers\""
    delete_event_organizers_by_pk(id: Int!): event_organizers
    "delete data from the table: \"event_participations\""
    delete_event_participations(
        "filter the rows which have to be deleted"
        where: event_participations_bool_exp!
    ): event_participations_mutation_response
    "delete single row from the table: \"event_participations\""
    delete_event_participations_by_pk(id: Int!): event_participations
    "delete data from the table: \"events\""
    delete_events(
        "filter the rows which have to be deleted"
        where: events_bool_exp!
    ): events_mutation_response
    "delete single row from the table: \"events\""
    delete_events_by_pk(id: String!): events
    "delete data from the table: \"events_categories\""
    delete_events_categories(
        "filter the rows which have to be deleted"
        where: events_categories_bool_exp!
    ): events_categories_mutation_response
    "delete single row from the table: \"events_categories\""
    delete_events_categories_by_pk(id: Int!): events_categories
    "delete data from the table: \"images_hashes\""
    delete_images_hashes(
        "filter the rows which have to be deleted"
        where: images_hashes_bool_exp!
    ): images_hashes_mutation_response
    "delete single row from the table: \"images_hashes\""
    delete_images_hashes_by_pk(image_url: String!): images_hashes
    "delete data from the table: \"memories\""
    delete_memories(
        "filter the rows which have to be deleted"
        where: memories_bool_exp!
    ): memories_mutation_response
    "delete single row from the table: \"memories\""
    delete_memories_by_pk(id: String!): memories
    "delete data from the table: \"memory_likes\""
    delete_memory_likes(
        "filter the rows which have to be deleted"
        where: memory_likes_bool_exp!
    ): memory_likes_mutation_response
    "delete single row from the table: \"memory_likes\""
    delete_memory_likes_by_pk(liker_address: String!, memory_id: String!): memory_likes
    "delete data from the table: \"notifications\""
    delete_notifications(
        "filter the rows which have to be deleted"
        where: notifications_bool_exp!
    ): notifications_mutation_response
    "delete single row from the table: \"notifications\""
    delete_notifications_by_pk(id: String!): notifications
    "delete data from the table: \"profile\""
    delete_profile(
        "filter the rows which have to be deleted"
        where: profile_bool_exp!
    ): profile_mutation_response
    "delete single row from the table: \"profile\""
    delete_profile_by_pk(address: String!): profile
    "delete data from the table: \"user_contacts\""
    delete_user_contacts(
        "filter the rows which have to be deleted"
        where: user_contacts_bool_exp!
    ): user_contacts_mutation_response
    "delete single row from the table: \"user_contacts\""
    delete_user_contacts_by_pk(id: String!): user_contacts
    "insert data into the table: \"bond_shared_contacts\""
    insert_bond_shared_contacts(
        "the rows to be inserted"
        objects: [bond_shared_contacts_insert_input!]!,
        "upsert condition"
        on_conflict: bond_shared_contacts_on_conflict
    ): bond_shared_contacts_mutation_response
    "insert a single row into the table: \"bond_shared_contacts\""
    insert_bond_shared_contacts_one(
        "the row to be inserted"
        object: bond_shared_contacts_insert_input!,
        "upsert condition"
        on_conflict: bond_shared_contacts_on_conflict
    ): bond_shared_contacts
    "insert data into the table: \"bonds\""
    insert_bonds(
        "the rows to be inserted"
        objects: [bonds_insert_input!]!,
        "upsert condition"
        on_conflict: bonds_on_conflict
    ): bonds_mutation_response
    "insert a single row into the table: \"bonds\""
    insert_bonds_one(
        "the row to be inserted"
        object: bonds_insert_input!,
        "upsert condition"
        on_conflict: bonds_on_conflict
    ): bonds
    "insert data into the table: \"event_categories\""
    insert_event_categories(
        "the rows to be inserted"
        objects: [event_categories_insert_input!]!,
        "upsert condition"
        on_conflict: event_categories_on_conflict
    ): event_categories_mutation_response
    "insert a single row into the table: \"event_categories\""
    insert_event_categories_one(
        "the row to be inserted"
        object: event_categories_insert_input!,
        "upsert condition"
        on_conflict: event_categories_on_conflict
    ): event_categories
    "insert data into the table: \"event_likes\""
    insert_event_likes(
        "the rows to be inserted"
        objects: [event_likes_insert_input!]!,
        "upsert condition"
        on_conflict: event_likes_on_conflict
    ): event_likes_mutation_response
    "insert a single row into the table: \"event_likes\""
    insert_event_likes_one(
        "the row to be inserted"
        object: event_likes_insert_input!,
        "upsert condition"
        on_conflict: event_likes_on_conflict
    ): event_likes
    "insert data into the table: \"event_organizers\""
    insert_event_organizers(
        "the rows to be inserted"
        objects: [event_organizers_insert_input!]!,
        "upsert condition"
        on_conflict: event_organizers_on_conflict
    ): event_organizers_mutation_response
    "insert a single row into the table: \"event_organizers\""
    insert_event_organizers_one(
        "the row to be inserted"
        object: event_organizers_insert_input!,
        "upsert condition"
        on_conflict: event_organizers_on_conflict
    ): event_organizers
    "insert data into the table: \"event_participations\""
    insert_event_participations(
        "the rows to be inserted"
        objects: [event_participations_insert_input!]!,
        "upsert condition"
        on_conflict: event_participations_on_conflict
    ): event_participations_mutation_response
    "insert a single row into the table: \"event_participations\""
    insert_event_participations_one(
        "the row to be inserted"
        object: event_participations_insert_input!,
        "upsert condition"
        on_conflict: event_participations_on_conflict
    ): event_participations
    "insert data into the table: \"events\""
    insert_events(
        "the rows to be inserted"
        objects: [events_insert_input!]!,
        "upsert condition"
        on_conflict: events_on_conflict
    ): events_mutation_response
    "insert data into the table: \"events_categories\""
    insert_events_categories(
        "the rows to be inserted"
        objects: [events_categories_insert_input!]!,
        "upsert condition"
        on_conflict: events_categories_on_conflict
    ): events_categories_mutation_response
    "insert a single row into the table: \"events_categories\""
    insert_events_categories_one(
        "the row to be inserted"
        object: events_categories_insert_input!,
        "upsert condition"
        on_conflict: events_categories_on_conflict
    ): events_categories
    "insert a single row into the table: \"events\""
    insert_events_one(
        "the row to be inserted"
        object: events_insert_input!,
        "upsert condition"
        on_conflict: events_on_conflict
    ): events
    "insert data into the table: \"images_hashes\""
    insert_images_hashes(
        "the rows to be inserted"
        objects: [images_hashes_insert_input!]!,
        "upsert condition"
        on_conflict: images_hashes_on_conflict
    ): images_hashes_mutation_response
    "insert a single row into the table: \"images_hashes\""
    insert_images_hashes_one(
        "the row to be inserted"
        object: images_hashes_insert_input!,
        "upsert condition"
        on_conflict: images_hashes_on_conflict
    ): images_hashes
    "insert data into the table: \"memories\""
    insert_memories(
        "the rows to be inserted"
        objects: [memories_insert_input!]!,
        "upsert condition"
        on_conflict: memories_on_conflict
    ): memories_mutation_response
    "insert a single row into the table: \"memories\""
    insert_memories_one(
        "the row to be inserted"
        object: memories_insert_input!,
        "upsert condition"
        on_conflict: memories_on_conflict
    ): memories
    "insert data into the table: \"memory_likes\""
    insert_memory_likes(
        "the rows to be inserted"
        objects: [memory_likes_insert_input!]!,
        "upsert condition"
        on_conflict: memory_likes_on_conflict
    ): memory_likes_mutation_response
    "insert a single row into the table: \"memory_likes\""
    insert_memory_likes_one(
        "the row to be inserted"
        object: memory_likes_insert_input!,
        "upsert condition"
        on_conflict: memory_likes_on_conflict
    ): memory_likes
    "insert data into the table: \"notifications\""
    insert_notifications(
        "the rows to be inserted"
        objects: [notifications_insert_input!]!,
        "upsert condition"
        on_conflict: notifications_on_conflict
    ): notifications_mutation_response
    "insert a single row into the table: \"notifications\""
    insert_notifications_one(
        "the row to be inserted"
        object: notifications_insert_input!,
        "upsert condition"
        on_conflict: notifications_on_conflict
    ): notifications
    "insert data into the table: \"profile\""
    insert_profile(
        "the rows to be inserted"
        objects: [profile_insert_input!]!,
        "upsert condition"
        on_conflict: profile_on_conflict
    ): profile_mutation_response
    "insert a single row into the table: \"profile\""
    insert_profile_one(
        "the row to be inserted"
        object: profile_insert_input!,
        "upsert condition"
        on_conflict: profile_on_conflict
    ): profile
    "insert data into the table: \"user_contacts\""
    insert_user_contacts(
        "the rows to be inserted"
        objects: [user_contacts_insert_input!]!,
        "upsert condition"
        on_conflict: user_contacts_on_conflict
    ): user_contacts_mutation_response
    "insert a single row into the table: \"user_contacts\""
    insert_user_contacts_one(
        "the row to be inserted"
        object: user_contacts_insert_input!,
        "upsert condition"
        on_conflict: user_contacts_on_conflict
    ): user_contacts
    "update data of the table: \"bond_shared_contacts\""
    update_bond_shared_contacts(
        "sets the columns of the filtered rows to the given values"
        _set: bond_shared_contacts_set_input,
        "filter the rows which have to be updated"
        where: bond_shared_contacts_bool_exp!
    ): bond_shared_contacts_mutation_response
    "update single row of the table: \"bond_shared_contacts\""
    update_bond_shared_contacts_by_pk(
        "sets the columns of the filtered rows to the given values"
        _set: bond_shared_contacts_set_input,
        pk_columns: bond_shared_contacts_pk_columns_input!
    ): bond_shared_contacts
    "update multiples rows of table: \"bond_shared_contacts\""
    update_bond_shared_contacts_many(
        "updates to execute, in order"
        updates: [bond_shared_contacts_updates!]!
    ): [bond_shared_contacts_mutation_response]
    "update data of the table: \"bonds\""
    update_bonds(
        "sets the columns of the filtered rows to the given values"
        _set: bonds_set_input,
        "filter the rows which have to be updated"
        where: bonds_bool_exp!
    ): bonds_mutation_response
    "update single row of the table: \"bonds\""
    update_bonds_by_pk(
        "sets the columns of the filtered rows to the given values"
        _set: bonds_set_input,
        pk_columns: bonds_pk_columns_input!
    ): bonds
    "update multiples rows of table: \"bonds\""
    update_bonds_many(
        "updates to execute, in order"
        updates: [bonds_updates!]!
    ): [bonds_mutation_response]
    "update data of the table: \"event_categories\""
    update_event_categories(
        "increments the numeric columns with given value of the filtered values"
        _inc: event_categories_inc_input,
        "sets the columns of the filtered rows to the given values"
        _set: event_categories_set_input,
        "filter the rows which have to be updated"
        where: event_categories_bool_exp!
    ): event_categories_mutation_response
    "update single row of the table: \"event_categories\""
    update_event_categories_by_pk(
        "increments the numeric columns with given value of the filtered values"
        _inc: event_categories_inc_input,
        "sets the columns of the filtered rows to the given values"
        _set: event_categories_set_input,
        pk_columns: event_categories_pk_columns_input!
    ): event_categories
    "update multiples rows of table: \"event_categories\""
    update_event_categories_many(
        "updates to execute, in order"
        updates: [event_categories_updates!]!
    ): [event_categories_mutation_response]
    "update data of the table: \"event_likes\""
    update_event_likes(
        "sets the columns of the filtered rows to the given values"
        _set: event_likes_set_input,
        "filter the rows which have to be updated"
        where: event_likes_bool_exp!
    ): event_likes_mutation_response
    "update single row of the table: \"event_likes\""
    update_event_likes_by_pk(
        "sets the columns of the filtered rows to the given values"
        _set: event_likes_set_input,
        pk_columns: event_likes_pk_columns_input!
    ): event_likes
    "update multiples rows of table: \"event_likes\""
    update_event_likes_many(
        "updates to execute, in order"
        updates: [event_likes_updates!]!
    ): [event_likes_mutation_response]
    "update data of the table: \"event_organizers\""
    update_event_organizers(
        "increments the numeric columns with given value of the filtered values"
        _inc: event_organizers_inc_input,
        "sets the columns of the filtered rows to the given values"
        _set: event_organizers_set_input,
        "filter the rows which have to be updated"
        where: event_organizers_bool_exp!
    ): event_organizers_mutation_response
    "update single row of the table: \"event_organizers\""
    update_event_organizers_by_pk(
        "increments the numeric columns with given value of the filtered values"
        _inc: event_organizers_inc_input,
        "sets the columns of the filtered rows to the given values"
        _set: event_organizers_set_input,
        pk_columns: event_organizers_pk_columns_input!
    ): event_organizers
    "update multiples rows of table: \"event_organizers\""
    update_event_organizers_many(
        "updates to execute, in order"
        updates: [event_organizers_updates!]!
    ): [event_organizers_mutation_response]
    "update data of the table: \"event_participations\""
    update_event_participations(
        "increments the numeric columns with given value of the filtered values"
        _inc: event_participations_inc_input,
        "sets the columns of the filtered rows to the given values"
        _set: event_participations_set_input,
        "filter the rows which have to be updated"
        where: event_participations_bool_exp!
    ): event_participations_mutation_response
    "update single row of the table: \"event_participations\""
    update_event_participations_by_pk(
        "increments the numeric columns with given value of the filtered values"
        _inc: event_participations_inc_input,
        "sets the columns of the filtered rows to the given values"
        _set: event_participations_set_input,
        pk_columns: event_participations_pk_columns_input!
    ): event_participations
    "update multiples rows of table: \"event_participations\""
    update_event_participations_many(
        "updates to execute, in order"
        updates: [event_participations_updates!]!
    ): [event_participations_mutation_response]
    "update data of the table: \"events\""
    update_events(
        "append existing jsonb value of filtered columns with new jsonb value"
        _append: events_append_input,
        "delete the field or element with specified path (for JSON arrays, negative integers count from the end)"
        _delete_at_path: events_delete_at_path_input,
        "delete the array element with specified index (negative integers count from the end). throws an error if top level container is not an array"
        _delete_elem: events_delete_elem_input,
        "delete key/value pair or string element. key/value pairs are matched based on their key value"
        _delete_key: events_delete_key_input,
        "prepend existing jsonb value of filtered columns with new jsonb value"
        _prepend: events_prepend_input,
        "sets the columns of the filtered rows to the given values"
        _set: events_set_input,
        "filter the rows which have to be updated"
        where: events_bool_exp!
    ): events_mutation_response
    "update single row of the table: \"events\""
    update_events_by_pk(
        "append existing jsonb value of filtered columns with new jsonb value"
        _append: events_append_input,
        "delete the field or element with specified path (for JSON arrays, negative integers count from the end)"
        _delete_at_path: events_delete_at_path_input,
        "delete the array element with specified index (negative integers count from the end). throws an error if top level container is not an array"
        _delete_elem: events_delete_elem_input,
        "delete key/value pair or string element. key/value pairs are matched based on their key value"
        _delete_key: events_delete_key_input,
        "prepend existing jsonb value of filtered columns with new jsonb value"
        _prepend: events_prepend_input,
        "sets the columns of the filtered rows to the given values"
        _set: events_set_input,
        pk_columns: events_pk_columns_input!
    ): events
    "update data of the table: \"events_categories\""
    update_events_categories(
        "increments the numeric columns with given value of the filtered values"
        _inc: events_categories_inc_input,
        "sets the columns of the filtered rows to the given values"
        _set: events_categories_set_input,
        "filter the rows which have to be updated"
        where: events_categories_bool_exp!
    ): events_categories_mutation_response
    "update single row of the table: \"events_categories\""
    update_events_categories_by_pk(
        "increments the numeric columns with given value of the filtered values"
        _inc: events_categories_inc_input,
        "sets the columns of the filtered rows to the given values"
        _set: events_categories_set_input,
        pk_columns: events_categories_pk_columns_input!
    ): events_categories
    "update multiples rows of table: \"events_categories\""
    update_events_categories_many(
        "updates to execute, in order"
        updates: [events_categories_updates!]!
    ): [events_categories_mutation_response]
    "update multiples rows of table: \"events\""
    update_events_many(
        "updates to execute, in order"
        updates: [events_updates!]!
    ): [events_mutation_response]
    "update data of the table: \"images_hashes\""
    update_images_hashes(
        "sets the columns of the filtered rows to the given values"
        _set: images_hashes_set_input,
        "filter the rows which have to be updated"
        where: images_hashes_bool_exp!
    ): images_hashes_mutation_response
    "update single row of the table: \"images_hashes\""
    update_images_hashes_by_pk(
        "sets the columns of the filtered rows to the given values"
        _set: images_hashes_set_input,
        pk_columns: images_hashes_pk_columns_input!
    ): images_hashes
    "update multiples rows of table: \"images_hashes\""
    update_images_hashes_many(
        "updates to execute, in order"
        updates: [images_hashes_updates!]!
    ): [images_hashes_mutation_response]
    "update data of the table: \"memories\""
    update_memories(
        "sets the columns of the filtered rows to the given values"
        _set: memories_set_input,
        "filter the rows which have to be updated"
        where: memories_bool_exp!
    ): memories_mutation_response
    "update single row of the table: \"memories\""
    update_memories_by_pk(
        "sets the columns of the filtered rows to the given values"
        _set: memories_set_input,
        pk_columns: memories_pk_columns_input!
    ): memories
    "update multiples rows of table: \"memories\""
    update_memories_many(
        "updates to execute, in order"
        updates: [memories_updates!]!
    ): [memories_mutation_response]
    "update data of the table: \"memory_likes\""
    update_memory_likes(
        "sets the columns of the filtered rows to the given values"
        _set: memory_likes_set_input,
        "filter the rows which have to be updated"
        where: memory_likes_bool_exp!
    ): memory_likes_mutation_response
    "update single row of the table: \"memory_likes\""
    update_memory_likes_by_pk(
        "sets the columns of the filtered rows to the given values"
        _set: memory_likes_set_input,
        pk_columns: memory_likes_pk_columns_input!
    ): memory_likes
    "update multiples rows of table: \"memory_likes\""
    update_memory_likes_many(
        "updates to execute, in order"
        updates: [memory_likes_updates!]!
    ): [memory_likes_mutation_response]
    "update data of the table: \"notifications\""
    update_notifications(
        "append existing jsonb value of filtered columns with new jsonb value"
        _append: notifications_append_input,
        "delete the field or element with specified path (for JSON arrays, negative integers count from the end)"
        _delete_at_path: notifications_delete_at_path_input,
        "delete the array element with specified index (negative integers count from the end). throws an error if top level container is not an array"
        _delete_elem: notifications_delete_elem_input,
        "delete key/value pair or string element. key/value pairs are matched based on their key value"
        _delete_key: notifications_delete_key_input,
        "prepend existing jsonb value of filtered columns with new jsonb value"
        _prepend: notifications_prepend_input,
        "sets the columns of the filtered rows to the given values"
        _set: notifications_set_input,
        "filter the rows which have to be updated"
        where: notifications_bool_exp!
    ): notifications_mutation_response
    "update single row of the table: \"notifications\""
    update_notifications_by_pk(
        "append existing jsonb value of filtered columns with new jsonb value"
        _append: notifications_append_input,
        "delete the field or element with specified path (for JSON arrays, negative integers count from the end)"
        _delete_at_path: notifications_delete_at_path_input,
        "delete the array element with specified index (negative integers count from the end). throws an error if top level container is not an array"
        _delete_elem: notifications_delete_elem_input,
        "delete key/value pair or string element. key/value pairs are matched based on their key value"
        _delete_key: notifications_delete_key_input,
        "prepend existing jsonb value of filtered columns with new jsonb value"
        _prepend: notifications_prepend_input,
        "sets the columns of the filtered rows to the given values"
        _set: notifications_set_input,
        pk_columns: notifications_pk_columns_input!
    ): notifications
    "update multiples rows of table: \"notifications\""
    update_notifications_many(
        "updates to execute, in order"
        updates: [notifications_updates!]!
    ): [notifications_mutation_response]
    "update data of the table: \"profile\""
    update_profile(
        "increments the numeric columns with given value of the filtered values"
        _inc: profile_inc_input,
        "sets the columns of the filtered rows to the given values"
        _set: profile_set_input,
        "filter the rows which have to be updated"
        where: profile_bool_exp!
    ): profile_mutation_response
    "update single row of the table: \"profile\""
    update_profile_by_pk(
        "increments the numeric columns with given value of the filtered values"
        _inc: profile_inc_input,
        "sets the columns of the filtered rows to the given values"
        _set: profile_set_input,
        pk_columns: profile_pk_columns_input!
    ): profile
    "update multiples rows of table: \"profile\""
    update_profile_many(
        "updates to execute, in order"
        updates: [profile_updates!]!
    ): [profile_mutation_response]
    "update data of the table: \"user_contacts\""
    update_user_contacts(
        "sets the columns of the filtered rows to the given values"
        _set: user_contacts_set_input,
        "filter the rows which have to be updated"
        where: user_contacts_bool_exp!
    ): user_contacts_mutation_response
    "update single row of the table: \"user_contacts\""
    update_user_contacts_by_pk(
        "sets the columns of the filtered rows to the given values"
        _set: user_contacts_set_input,
        pk_columns: user_contacts_pk_columns_input!
    ): user_contacts
    "update multiples rows of table: \"user_contacts\""
    update_user_contacts_many(
        "updates to execute, in order"
        updates: [user_contacts_updates!]!
    ): [user_contacts_mutation_response]
}

"columns and relationships of \"notifications\""
type notifications {
    additional_data(
        "JSON select path"
        path: String
    ): jsonb
    body: String
    id: String!
    image_url: String
    timestamp: timestamptz!
    title: String
    type: String!
    user_address: String!
}

"aggregated selection of \"notifications\""
type notifications_aggregate {
    aggregate: notifications_aggregate_fields
    nodes: [notifications!]!
}

"aggregate fields of \"notifications\""
type notifications_aggregate_fields {
    count(columns: [notifications_select_column!], distinct: Boolean): Int!
    max: notifications_max_fields
    min: notifications_min_fields
}

"aggregate max on columns"
type notifications_max_fields {
    body: String
    id: String
    image_url: String
    timestamp: timestamptz
    title: String
    type: String
    user_address: String
}

"aggregate min on columns"
type notifications_min_fields {
    body: String
    id: String
    image_url: String
    timestamp: timestamptz
    title: String
    type: String
    user_address: String
}

"response of any mutation on the table \"notifications\""
type notifications_mutation_response {
    "number of rows affected by the mutation"
    affected_rows: Int!
    "data from the rows affected by the mutation"
    returning: [notifications!]!
}

"columns and relationships of \"profile\""
type profile {
    address: String!
    bio: String!
    cover_pic: String!
    creation_time: timestamp!
    dtag: String!
    height: bigint!
    nickname: String!
    profile_pic: String!
}

"aggregated selection of \"profile\""
type profile_aggregate {
    aggregate: profile_aggregate_fields
    nodes: [profile!]!
}

"aggregate fields of \"profile\""
type profile_aggregate_fields {
    avg: profile_avg_fields
    count(columns: [profile_select_column!], distinct: Boolean): Int!
    max: profile_max_fields
    min: profile_min_fields
    stddev: profile_stddev_fields
    stddev_pop: profile_stddev_pop_fields
    stddev_samp: profile_stddev_samp_fields
    sum: profile_sum_fields
    var_pop: profile_var_pop_fields
    var_samp: profile_var_samp_fields
    variance: profile_variance_fields
}

"aggregate avg on columns"
type profile_avg_fields {
    height: Float
}

"aggregate max on columns"
type profile_max_fields {
    address: String
    bio: String
    cover_pic: String
    creation_time: timestamp
    dtag: String
    height: bigint
    nickname: String
    profile_pic: String
}

"aggregate min on columns"
type profile_min_fields {
    address: String
    bio: String
    cover_pic: String
    creation_time: timestamp
    dtag: String
    height: bigint
    nickname: String
    profile_pic: String
}

"response of any mutation on the table \"profile\""
type profile_mutation_response {
    "number of rows affected by the mutation"
    affected_rows: Int!
    "data from the rows affected by the mutation"
    returning: [profile!]!
}

"aggregate stddev on columns"
type profile_stddev_fields {
    height: Float
}

"aggregate stddev_pop on columns"
type profile_stddev_pop_fields {
    height: Float
}

"aggregate stddev_samp on columns"
type profile_stddev_samp_fields {
    height: Float
}

"aggregate sum on columns"
type profile_sum_fields {
    height: bigint
}

"aggregate var_pop on columns"
type profile_var_pop_fields {
    height: Float
}

"aggregate var_samp on columns"
type profile_var_samp_fields {
    height: Float
}

"aggregate variance on columns"
type profile_variance_fields {
    height: Float
}

type query_root {
    "fetch data from the table: \"bond_shared_contacts\""
    bond_shared_contacts(
        "distinct select on columns"
        distinct_on: [bond_shared_contacts_select_column!],
        "limit the number of rows returned"
        limit: Int,
        "skip the first n rows. Use only with order_by"
        offset: Int,
        "sort the rows by one or more columns"
        order_by: [bond_shared_contacts_order_by!],
        "filter the rows returned"
        where: bond_shared_contacts_bool_exp
    ): [bond_shared_contacts!]!
    "fetch aggregated fields from the table: \"bond_shared_contacts\""
    bond_shared_contacts_aggregate(
        "distinct select on columns"
        distinct_on: [bond_shared_contacts_select_column!],
        "limit the number of rows returned"
        limit: Int,
        "skip the first n rows. Use only with order_by"
        offset: Int,
        "sort the rows by one or more columns"
        order_by: [bond_shared_contacts_order_by!],
        "filter the rows returned"
        where: bond_shared_contacts_bool_exp
    ): bond_shared_contacts_aggregate!
    "fetch data from the table: \"bond_shared_contacts\" using primary key columns"
    bond_shared_contacts_by_pk(id: String!): bond_shared_contacts
    "An array relationship"
    bonds(
        "distinct select on columns"
        distinct_on: [bonds_select_column!],
        "limit the number of rows returned"
        limit: Int,
        "skip the first n rows. Use only with order_by"
        offset: Int,
        "sort the rows by one or more columns"
        order_by: [bonds_order_by!],
        "filter the rows returned"
        where: bonds_bool_exp
    ): [bonds!]!
    "An aggregate relationship"
    bonds_aggregate(
        "distinct select on columns"
        distinct_on: [bonds_select_column!],
        "limit the number of rows returned"
        limit: Int,
        "skip the first n rows. Use only with order_by"
        offset: Int,
        "sort the rows by one or more columns"
        order_by: [bonds_order_by!],
        "filter the rows returned"
        where: bonds_bool_exp
    ): bonds_aggregate!
    "fetch data from the table: \"bonds\" using primary key columns"
    bonds_by_pk(id: String!): bonds
    "fetch data from the table: \"event_categories\""
    event_categories(
        "distinct select on columns"
        distinct_on: [event_categories_select_column!],
        "limit the number of rows returned"
        limit: Int,
        "skip the first n rows. Use only with order_by"
        offset: Int,
        "sort the rows by one or more columns"
        order_by: [event_categories_order_by!],
        "filter the rows returned"
        where: event_categories_bool_exp
    ): [event_categories!]!
    "fetch aggregated fields from the table: \"event_categories\""
    event_categories_aggregate(
        "distinct select on columns"
        distinct_on: [event_categories_select_column!],
        "limit the number of rows returned"
        limit: Int,
        "skip the first n rows. Use only with order_by"
        offset: Int,
        "sort the rows by one or more columns"
        order_by: [event_categories_order_by!],
        "filter the rows returned"
        where: event_categories_bool_exp
    ): event_categories_aggregate!
    "fetch data from the table: \"event_categories\" using primary key columns"
    event_categories_by_pk(id: Int!): event_categories
    "fetch data from the table: \"event_likes\""
    event_likes(
        "distinct select on columns"
        distinct_on: [event_likes_select_column!],
        "limit the number of rows returned"
        limit: Int,
        "skip the first n rows. Use only with order_by"
        offset: Int,
        "sort the rows by one or more columns"
        order_by: [event_likes_order_by!],
        "filter the rows returned"
        where: event_likes_bool_exp
    ): [event_likes!]!
    "fetch aggregated fields from the table: \"event_likes\""
    event_likes_aggregate(
        "distinct select on columns"
        distinct_on: [event_likes_select_column!],
        "limit the number of rows returned"
        limit: Int,
        "skip the first n rows. Use only with order_by"
        offset: Int,
        "sort the rows by one or more columns"
        order_by: [event_likes_order_by!],
        "filter the rows returned"
        where: event_likes_bool_exp
    ): event_likes_aggregate!
    "fetch data from the table: \"event_likes\" using primary key columns"
    event_likes_by_pk(event_id: String!, liker_address: String!): event_likes
    "fetch data from the table: \"event_organizers\""
    event_organizers(
        "distinct select on columns"
        distinct_on: [event_organizers_select_column!],
        "limit the number of rows returned"
        limit: Int,
        "skip the first n rows. Use only with order_by"
        offset: Int,
        "sort the rows by one or more columns"
        order_by: [event_organizers_order_by!],
        "filter the rows returned"
        where: event_organizers_bool_exp
    ): [event_organizers!]!
    "fetch aggregated fields from the table: \"event_organizers\""
    event_organizers_aggregate(
        "distinct select on columns"
        distinct_on: [event_organizers_select_column!],
        "limit the number of rows returned"
        limit: Int,
        "skip the first n rows. Use only with order_by"
        offset: Int,
        "sort the rows by one or more columns"
        order_by: [event_organizers_order_by!],
        "filter the rows returned"
        where: event_organizers_bool_exp
    ): event_organizers_aggregate!
    "fetch data from the table: \"event_organizers\" using primary key columns"
    event_organizers_by_pk(id: Int!): event_organizers
    "fetch data from the table: \"event_participations\""
    event_participations(
        "distinct select on columns"
        distinct_on: [event_participations_select_column!],
        "limit the number of rows returned"
        limit: Int,
        "skip the first n rows. Use only with order_by"
        offset: Int,
        "sort the rows by one or more columns"
        order_by: [event_participations_order_by!],
        "filter the rows returned"
        where: event_participations_bool_exp
    ): [event_participations!]!
    "fetch aggregated fields from the table: \"event_participations\""
    event_participations_aggregate(
        "distinct select on columns"
        distinct_on: [event_participations_select_column!],
        "limit the number of rows returned"
        limit: Int,
        "skip the first n rows. Use only with order_by"
        offset: Int,
        "sort the rows by one or more columns"
        order_by: [event_participations_order_by!],
        "filter the rows returned"
        where: event_participations_bool_exp
    ): event_participations_aggregate!
    "fetch data from the table: \"event_participations\" using primary key columns"
    event_participations_by_pk(id: Int!): event_participations
    "fetch data from the table: \"event_tags\""
    event_tags(
        "distinct select on columns"
        distinct_on: [event_tags_select_column!],
        "limit the number of rows returned"
        limit: Int,
        "skip the first n rows. Use only with order_by"
        offset: Int,
        "sort the rows by one or more columns"
        order_by: [event_tags_order_by!],
        "filter the rows returned"
        where: event_tags_bool_exp
    ): [event_tags!]!
    "fetch aggregated fields from the table: \"event_tags\""
    event_tags_aggregate(
        "distinct select on columns"
        distinct_on: [event_tags_select_column!],
        "limit the number of rows returned"
        limit: Int,
        "skip the first n rows. Use only with order_by"
        offset: Int,
        "sort the rows by one or more columns"
        order_by: [event_tags_order_by!],
        "filter the rows returned"
        where: event_tags_bool_exp
    ): event_tags_aggregate!
    "fetch data from the table: \"events\""
    events(
        "distinct select on columns"
        distinct_on: [events_select_column!],
        "limit the number of rows returned"
        limit: Int,
        "skip the first n rows. Use only with order_by"
        offset: Int,
        "sort the rows by one or more columns"
        order_by: [events_order_by!],
        "filter the rows returned"
        where: events_bool_exp
    ): [events!]!
    "fetch aggregated fields from the table: \"events\""
    events_aggregate(
        "distinct select on columns"
        distinct_on: [events_select_column!],
        "limit the number of rows returned"
        limit: Int,
        "skip the first n rows. Use only with order_by"
        offset: Int,
        "sort the rows by one or more columns"
        order_by: [events_order_by!],
        "filter the rows returned"
        where: events_bool_exp
    ): events_aggregate!
    "fetch data from the table: \"events\" using primary key columns"
    events_by_pk(id: String!): events
    "fetch data from the table: \"events_categories\""
    events_categories(
        "distinct select on columns"
        distinct_on: [events_categories_select_column!],
        "limit the number of rows returned"
        limit: Int,
        "skip the first n rows. Use only with order_by"
        offset: Int,
        "sort the rows by one or more columns"
        order_by: [events_categories_order_by!],
        "filter the rows returned"
        where: events_categories_bool_exp
    ): [events_categories!]!
    "fetch aggregated fields from the table: \"events_categories\""
    events_categories_aggregate(
        "distinct select on columns"
        distinct_on: [events_categories_select_column!],
        "limit the number of rows returned"
        limit: Int,
        "skip the first n rows. Use only with order_by"
        offset: Int,
        "sort the rows by one or more columns"
        order_by: [events_categories_order_by!],
        "filter the rows returned"
        where: events_categories_bool_exp
    ): events_categories_aggregate!
    "fetch data from the table: \"events_categories\" using primary key columns"
    events_categories_by_pk(id: Int!): events_categories
    "fetch data from the table: \"images_hashes\""
    images_hashes(
        "distinct select on columns"
        distinct_on: [images_hashes_select_column!],
        "limit the number of rows returned"
        limit: Int,
        "skip the first n rows. Use only with order_by"
        offset: Int,
        "sort the rows by one or more columns"
        order_by: [images_hashes_order_by!],
        "filter the rows returned"
        where: images_hashes_bool_exp
    ): [images_hashes!]!
    "fetch aggregated fields from the table: \"images_hashes\""
    images_hashes_aggregate(
        "distinct select on columns"
        distinct_on: [images_hashes_select_column!],
        "limit the number of rows returned"
        limit: Int,
        "skip the first n rows. Use only with order_by"
        offset: Int,
        "sort the rows by one or more columns"
        order_by: [images_hashes_order_by!],
        "filter the rows returned"
        where: images_hashes_bool_exp
    ): images_hashes_aggregate!
    "fetch data from the table: \"images_hashes\" using primary key columns"
    images_hashes_by_pk(image_url: String!): images_hashes
    "An array relationship"
    memories(
        "distinct select on columns"
        distinct_on: [memories_select_column!],
        "limit the number of rows returned"
        limit: Int,
        "skip the first n rows. Use only with order_by"
        offset: Int,
        "sort the rows by one or more columns"
        order_by: [memories_order_by!],
        "filter the rows returned"
        where: memories_bool_exp
    ): [memories!]!
    "An aggregate relationship"
    memories_aggregate(
        "distinct select on columns"
        distinct_on: [memories_select_column!],
        "limit the number of rows returned"
        limit: Int,
        "skip the first n rows. Use only with order_by"
        offset: Int,
        "sort the rows by one or more columns"
        order_by: [memories_order_by!],
        "filter the rows returned"
        where: memories_bool_exp
    ): memories_aggregate!
    "fetch data from the table: \"memories\" using primary key columns"
    memories_by_pk(id: String!): memories
    "fetch data from the table: \"memory_likes\""
    memory_likes(
        "distinct select on columns"
        distinct_on: [memory_likes_select_column!],
        "limit the number of rows returned"
        limit: Int,
        "skip the first n rows. Use only with order_by"
        offset: Int,
        "sort the rows by one or more columns"
        order_by: [memory_likes_order_by!],
        "filter the rows returned"
        where: memory_likes_bool_exp
    ): [memory_likes!]!
    "fetch aggregated fields from the table: \"memory_likes\""
    memory_likes_aggregate(
        "distinct select on columns"
        distinct_on: [memory_likes_select_column!],
        "limit the number of rows returned"
        limit: Int,
        "skip the first n rows. Use only with order_by"
        offset: Int,
        "sort the rows by one or more columns"
        order_by: [memory_likes_order_by!],
        "filter the rows returned"
        where: memory_likes_bool_exp
    ): memory_likes_aggregate!
    "fetch data from the table: \"memory_likes\" using primary key columns"
    memory_likes_by_pk(liker_address: String!, memory_id: String!): memory_likes
    "fetch data from the table: \"notifications\""
    notifications(
        "distinct select on columns"
        distinct_on: [notifications_select_column!],
        "limit the number of rows returned"
        limit: Int,
        "skip the first n rows. Use only with order_by"
        offset: Int,
        "sort the rows by one or more columns"
        order_by: [notifications_order_by!],
        "filter the rows returned"
        where: notifications_bool_exp
    ): [notifications!]!
    "fetch aggregated fields from the table: \"notifications\""
    notifications_aggregate(
        "distinct select on columns"
        distinct_on: [notifications_select_column!],
        "limit the number of rows returned"
        limit: Int,
        "skip the first n rows. Use only with order_by"
        offset: Int,
        "sort the rows by one or more columns"
        order_by: [notifications_order_by!],
        "filter the rows returned"
        where: notifications_bool_exp
    ): notifications_aggregate!
    "fetch data from the table: \"notifications\" using primary key columns"
    notifications_by_pk(id: String!): notifications
    "fetch data from the table: \"profile\""
    profile(
        "distinct select on columns"
        distinct_on: [profile_select_column!],
        "limit the number of rows returned"
        limit: Int,
        "skip the first n rows. Use only with order_by"
        offset: Int,
        "sort the rows by one or more columns"
        order_by: [profile_order_by!],
        "filter the rows returned"
        where: profile_bool_exp
    ): [profile!]!
    "fetch aggregated fields from the table: \"profile\""
    profile_aggregate(
        "distinct select on columns"
        distinct_on: [profile_select_column!],
        "limit the number of rows returned"
        limit: Int,
        "skip the first n rows. Use only with order_by"
        offset: Int,
        "sort the rows by one or more columns"
        order_by: [profile_order_by!],
        "filter the rows returned"
        where: profile_bool_exp
    ): profile_aggregate!
    "fetch data from the table: \"profile\" using primary key columns"
    profile_by_pk(address: String!): profile
    "fetch data from the table: \"user_contacts\""
    user_contacts(
        "distinct select on columns"
        distinct_on: [user_contacts_select_column!],
        "limit the number of rows returned"
        limit: Int,
        "skip the first n rows. Use only with order_by"
        offset: Int,
        "sort the rows by one or more columns"
        order_by: [user_contacts_order_by!],
        "filter the rows returned"
        where: user_contacts_bool_exp
    ): [user_contacts!]!
    "fetch aggregated fields from the table: \"user_contacts\""
    user_contacts_aggregate(
        "distinct select on columns"
        distinct_on: [user_contacts_select_column!],
        "limit the number of rows returned"
        limit: Int,
        "skip the first n rows. Use only with order_by"
        offset: Int,
        "sort the rows by one or more columns"
        order_by: [user_contacts_order_by!],
        "filter the rows returned"
        where: user_contacts_bool_exp
    ): user_contacts_aggregate!
    "fetch data from the table: \"user_contacts\" using primary key columns"
    user_contacts_by_pk(id: String!): user_contacts
}

type subscription_root {
    "fetch data from the table: \"bond_shared_contacts\""
    bond_shared_contacts(
        "distinct select on columns"
        distinct_on: [bond_shared_contacts_select_column!],
        "limit the number of rows returned"
        limit: Int,
        "skip the first n rows. Use only with order_by"
        offset: Int,
        "sort the rows by one or more columns"
        order_by: [bond_shared_contacts_order_by!],
        "filter the rows returned"
        where: bond_shared_contacts_bool_exp
    ): [bond_shared_contacts!]!
    "fetch aggregated fields from the table: \"bond_shared_contacts\""
    bond_shared_contacts_aggregate(
        "distinct select on columns"
        distinct_on: [bond_shared_contacts_select_column!],
        "limit the number of rows returned"
        limit: Int,
        "skip the first n rows. Use only with order_by"
        offset: Int,
        "sort the rows by one or more columns"
        order_by: [bond_shared_contacts_order_by!],
        "filter the rows returned"
        where: bond_shared_contacts_bool_exp
    ): bond_shared_contacts_aggregate!
    "fetch data from the table: \"bond_shared_contacts\" using primary key columns"
    bond_shared_contacts_by_pk(id: String!): bond_shared_contacts
    "fetch data from the table in a streaming manner: \"bond_shared_contacts\""
    bond_shared_contacts_stream(
        "maximum number of rows returned in a single batch"
        batch_size: Int!,
        "cursor to stream the results returned by the query"
        cursor: [bond_shared_contacts_stream_cursor_input]!,
        "filter the rows returned"
        where: bond_shared_contacts_bool_exp
    ): [bond_shared_contacts!]!
    "An array relationship"
    bonds(
        "distinct select on columns"
        distinct_on: [bonds_select_column!],
        "limit the number of rows returned"
        limit: Int,
        "skip the first n rows. Use only with order_by"
        offset: Int,
        "sort the rows by one or more columns"
        order_by: [bonds_order_by!],
        "filter the rows returned"
        where: bonds_bool_exp
    ): [bonds!]!
    "An aggregate relationship"
    bonds_aggregate(
        "distinct select on columns"
        distinct_on: [bonds_select_column!],
        "limit the number of rows returned"
        limit: Int,
        "skip the first n rows. Use only with order_by"
        offset: Int,
        "sort the rows by one or more columns"
        order_by: [bonds_order_by!],
        "filter the rows returned"
        where: bonds_bool_exp
    ): bonds_aggregate!
    "fetch data from the table: \"bonds\" using primary key columns"
    bonds_by_pk(id: String!): bonds
    "fetch data from the table in a streaming manner: \"bonds\""
    bonds_stream(
        "maximum number of rows returned in a single batch"
        batch_size: Int!,
        "cursor to stream the results returned by the query"
        cursor: [bonds_stream_cursor_input]!,
        "filter the rows returned"
        where: bonds_bool_exp
    ): [bonds!]!
    "fetch data from the table: \"event_categories\""
    event_categories(
        "distinct select on columns"
        distinct_on: [event_categories_select_column!],
        "limit the number of rows returned"
        limit: Int,
        "skip the first n rows. Use only with order_by"
        offset: Int,
        "sort the rows by one or more columns"
        order_by: [event_categories_order_by!],
        "filter the rows returned"
        where: event_categories_bool_exp
    ): [event_categories!]!
    "fetch aggregated fields from the table: \"event_categories\""
    event_categories_aggregate(
        "distinct select on columns"
        distinct_on: [event_categories_select_column!],
        "limit the number of rows returned"
        limit: Int,
        "skip the first n rows. Use only with order_by"
        offset: Int,
        "sort the rows by one or more columns"
        order_by: [event_categories_order_by!],
        "filter the rows returned"
        where: event_categories_bool_exp
    ): event_categories_aggregate!
    "fetch data from the table: \"event_categories\" using primary key columns"
    event_categories_by_pk(id: Int!): event_categories
    "fetch data from the table in a streaming manner: \"event_categories\""
    event_categories_stream(
        "maximum number of rows returned in a single batch"
        batch_size: Int!,
        "cursor to stream the results returned by the query"
        cursor: [event_categories_stream_cursor_input]!,
        "filter the rows returned"
        where: event_categories_bool_exp
    ): [event_categories!]!
    "fetch data from the table: \"event_likes\""
    event_likes(
        "distinct select on columns"
        distinct_on: [event_likes_select_column!],
        "limit the number of rows returned"
        limit: Int,
        "skip the first n rows. Use only with order_by"
        offset: Int,
        "sort the rows by one or more columns"
        order_by: [event_likes_order_by!],
        "filter the rows returned"
        where: event_likes_bool_exp
    ): [event_likes!]!
    "fetch aggregated fields from the table: \"event_likes\""
    event_likes_aggregate(
        "distinct select on columns"
        distinct_on: [event_likes_select_column!],
        "limit the number of rows returned"
        limit: Int,
        "skip the first n rows. Use only with order_by"
        offset: Int,
        "sort the rows by one or more columns"
        order_by: [event_likes_order_by!],
        "filter the rows returned"
        where: event_likes_bool_exp
    ): event_likes_aggregate!
    "fetch data from the table: \"event_likes\" using primary key columns"
    event_likes_by_pk(event_id: String!, liker_address: String!): event_likes
    "fetch data from the table in a streaming manner: \"event_likes\""
    event_likes_stream(
        "maximum number of rows returned in a single batch"
        batch_size: Int!,
        "cursor to stream the results returned by the query"
        cursor: [event_likes_stream_cursor_input]!,
        "filter the rows returned"
        where: event_likes_bool_exp
    ): [event_likes!]!
    "fetch data from the table: \"event_organizers\""
    event_organizers(
        "distinct select on columns"
        distinct_on: [event_organizers_select_column!],
        "limit the number of rows returned"
        limit: Int,
        "skip the first n rows. Use only with order_by"
        offset: Int,
        "sort the rows by one or more columns"
        order_by: [event_organizers_order_by!],
        "filter the rows returned"
        where: event_organizers_bool_exp
    ): [event_organizers!]!
    "fetch aggregated fields from the table: \"event_organizers\""
    event_organizers_aggregate(
        "distinct select on columns"
        distinct_on: [event_organizers_select_column!],
        "limit the number of rows returned"
        limit: Int,
        "skip the first n rows. Use only with order_by"
        offset: Int,
        "sort the rows by one or more columns"
        order_by: [event_organizers_order_by!],
        "filter the rows returned"
        where: event_organizers_bool_exp
    ): event_organizers_aggregate!
    "fetch data from the table: \"event_organizers\" using primary key columns"
    event_organizers_by_pk(id: Int!): event_organizers
    "fetch data from the table in a streaming manner: \"event_organizers\""
    event_organizers_stream(
        "maximum number of rows returned in a single batch"
        batch_size: Int!,
        "cursor to stream the results returned by the query"
        cursor: [event_organizers_stream_cursor_input]!,
        "filter the rows returned"
        where: event_organizers_bool_exp
    ): [event_organizers!]!
    "fetch data from the table: \"event_participations\""
    event_participations(
        "distinct select on columns"
        distinct_on: [event_participations_select_column!],
        "limit the number of rows returned"
        limit: Int,
        "skip the first n rows. Use only with order_by"
        offset: Int,
        "sort the rows by one or more columns"
        order_by: [event_participations_order_by!],
        "filter the rows returned"
        where: event_participations_bool_exp
    ): [event_participations!]!
    "fetch aggregated fields from the table: \"event_participations\""
    event_participations_aggregate(
        "distinct select on columns"
        distinct_on: [event_participations_select_column!],
        "limit the number of rows returned"
        limit: Int,
        "skip the first n rows. Use only with order_by"
        offset: Int,
        "sort the rows by one or more columns"
        order_by: [event_participations_order_by!],
        "filter the rows returned"
        where: event_participations_bool_exp
    ): event_participations_aggregate!
    "fetch data from the table: \"event_participations\" using primary key columns"
    event_participations_by_pk(id: Int!): event_participations
    "fetch data from the table in a streaming manner: \"event_participations\""
    event_participations_stream(
        "maximum number of rows returned in a single batch"
        batch_size: Int!,
        "cursor to stream the results returned by the query"
        cursor: [event_participations_stream_cursor_input]!,
        "filter the rows returned"
        where: event_participations_bool_exp
    ): [event_participations!]!
    "fetch data from the table: \"event_tags\""
    event_tags(
        "distinct select on columns"
        distinct_on: [event_tags_select_column!],
        "limit the number of rows returned"
        limit: Int,
        "skip the first n rows. Use only with order_by"
        offset: Int,
        "sort the rows by one or more columns"
        order_by: [event_tags_order_by!],
        "filter the rows returned"
        where: event_tags_bool_exp
    ): [event_tags!]!
    "fetch aggregated fields from the table: \"event_tags\""
    event_tags_aggregate(
        "distinct select on columns"
        distinct_on: [event_tags_select_column!],
        "limit the number of rows returned"
        limit: Int,
        "skip the first n rows. Use only with order_by"
        offset: Int,
        "sort the rows by one or more columns"
        order_by: [event_tags_order_by!],
        "filter the rows returned"
        where: event_tags_bool_exp
    ): event_tags_aggregate!
    "fetch data from the table in a streaming manner: \"event_tags\""
    event_tags_stream(
        "maximum number of rows returned in a single batch"
        batch_size: Int!,
        "cursor to stream the results returned by the query"
        cursor: [event_tags_stream_cursor_input]!,
        "filter the rows returned"
        where: event_tags_bool_exp
    ): [event_tags!]!
    "fetch data from the table: \"events\""
    events(
        "distinct select on columns"
        distinct_on: [events_select_column!],
        "limit the number of rows returned"
        limit: Int,
        "skip the first n rows. Use only with order_by"
        offset: Int,
        "sort the rows by one or more columns"
        order_by: [events_order_by!],
        "filter the rows returned"
        where: events_bool_exp
    ): [events!]!
    "fetch aggregated fields from the table: \"events\""
    events_aggregate(
        "distinct select on columns"
        distinct_on: [events_select_column!],
        "limit the number of rows returned"
        limit: Int,
        "skip the first n rows. Use only with order_by"
        offset: Int,
        "sort the rows by one or more columns"
        order_by: [events_order_by!],
        "filter the rows returned"
        where: events_bool_exp
    ): events_aggregate!
    "fetch data from the table: \"events\" using primary key columns"
    events_by_pk(id: String!): events
    "fetch data from the table: \"events_categories\""
    events_categories(
        "distinct select on columns"
        distinct_on: [events_categories_select_column!],
        "limit the number of rows returned"
        limit: Int,
        "skip the first n rows. Use only with order_by"
        offset: Int,
        "sort the rows by one or more columns"
        order_by: [events_categories_order_by!],
        "filter the rows returned"
        where: events_categories_bool_exp
    ): [events_categories!]!
    "fetch aggregated fields from the table: \"events_categories\""
    events_categories_aggregate(
        "distinct select on columns"
        distinct_on: [events_categories_select_column!],
        "limit the number of rows returned"
        limit: Int,
        "skip the first n rows. Use only with order_by"
        offset: Int,
        "sort the rows by one or more columns"
        order_by: [events_categories_order_by!],
        "filter the rows returned"
        where: events_categories_bool_exp
    ): events_categories_aggregate!
    "fetch data from the table: \"events_categories\" using primary key columns"
    events_categories_by_pk(id: Int!): events_categories
    "fetch data from the table in a streaming manner: \"events_categories\""
    events_categories_stream(
        "maximum number of rows returned in a single batch"
        batch_size: Int!,
        "cursor to stream the results returned by the query"
        cursor: [events_categories_stream_cursor_input]!,
        "filter the rows returned"
        where: events_categories_bool_exp
    ): [events_categories!]!
    "fetch data from the table in a streaming manner: \"events\""
    events_stream(
        "maximum number of rows returned in a single batch"
        batch_size: Int!,
        "cursor to stream the results returned by the query"
        cursor: [events_stream_cursor_input]!,
        "filter the rows returned"
        where: events_bool_exp
    ): [events!]!
    "fetch data from the table: \"images_hashes\""
    images_hashes(
        "distinct select on columns"
        distinct_on: [images_hashes_select_column!],
        "limit the number of rows returned"
        limit: Int,
        "skip the first n rows. Use only with order_by"
        offset: Int,
        "sort the rows by one or more columns"
        order_by: [images_hashes_order_by!],
        "filter the rows returned"
        where: images_hashes_bool_exp
    ): [images_hashes!]!
    "fetch aggregated fields from the table: \"images_hashes\""
    images_hashes_aggregate(
        "distinct select on columns"
        distinct_on: [images_hashes_select_column!],
        "limit the number of rows returned"
        limit: Int,
        "skip the first n rows. Use only with order_by"
        offset: Int,
        "sort the rows by one or more columns"
        order_by: [images_hashes_order_by!],
        "filter the rows returned"
        where: images_hashes_bool_exp
    ): images_hashes_aggregate!
    "fetch data from the table: \"images_hashes\" using primary key columns"
    images_hashes_by_pk(image_url: String!): images_hashes
    "fetch data from the table in a streaming manner: \"images_hashes\""
    images_hashes_stream(
        "maximum number of rows returned in a single batch"
        batch_size: Int!,
        "cursor to stream the results returned by the query"
        cursor: [images_hashes_stream_cursor_input]!,
        "filter the rows returned"
        where: images_hashes_bool_exp
    ): [images_hashes!]!
    "An array relationship"
    memories(
        "distinct select on columns"
        distinct_on: [memories_select_column!],
        "limit the number of rows returned"
        limit: Int,
        "skip the first n rows. Use only with order_by"
        offset: Int,
        "sort the rows by one or more columns"
        order_by: [memories_order_by!],
        "filter the rows returned"
        where: memories_bool_exp
    ): [memories!]!
    "An aggregate relationship"
    memories_aggregate(
        "distinct select on columns"
        distinct_on: [memories_select_column!],
        "limit the number of rows returned"
        limit: Int,
        "skip the first n rows. Use only with order_by"
        offset: Int,
        "sort the rows by one or more columns"
        order_by: [memories_order_by!],
        "filter the rows returned"
        where: memories_bool_exp
    ): memories_aggregate!
    "fetch data from the table: \"memories\" using primary key columns"
    memories_by_pk(id: String!): memories
    "fetch data from the table in a streaming manner: \"memories\""
    memories_stream(
        "maximum number of rows returned in a single batch"
        batch_size: Int!,
        "cursor to stream the results returned by the query"
        cursor: [memories_stream_cursor_input]!,
        "filter the rows returned"
        where: memories_bool_exp
    ): [memories!]!
    "fetch data from the table: \"memory_likes\""
    memory_likes(
        "distinct select on columns"
        distinct_on: [memory_likes_select_column!],
        "limit the number of rows returned"
        limit: Int,
        "skip the first n rows. Use only with order_by"
        offset: Int,
        "sort the rows by one or more columns"
        order_by: [memory_likes_order_by!],
        "filter the rows returned"
        where: memory_likes_bool_exp
    ): [memory_likes!]!
    "fetch aggregated fields from the table: \"memory_likes\""
    memory_likes_aggregate(
        "distinct select on columns"
        distinct_on: [memory_likes_select_column!],
        "limit the number of rows returned"
        limit: Int,
        "skip the first n rows. Use only with order_by"
        offset: Int,
        "sort the rows by one or more columns"
        order_by: [memory_likes_order_by!],
        "filter the rows returned"
        where: memory_likes_bool_exp
    ): memory_likes_aggregate!
    "fetch data from the table: \"memory_likes\" using primary key columns"
    memory_likes_by_pk(liker_address: String!, memory_id: String!): memory_likes
    "fetch data from the table in a streaming manner: \"memory_likes\""
    memory_likes_stream(
        "maximum number of rows returned in a single batch"
        batch_size: Int!,
        "cursor to stream the results returned by the query"
        cursor: [memory_likes_stream_cursor_input]!,
        "filter the rows returned"
        where: memory_likes_bool_exp
    ): [memory_likes!]!
    "fetch data from the table: \"notifications\""
    notifications(
        "distinct select on columns"
        distinct_on: [notifications_select_column!],
        "limit the number of rows returned"
        limit: Int,
        "skip the first n rows. Use only with order_by"
        offset: Int,
        "sort the rows by one or more columns"
        order_by: [notifications_order_by!],
        "filter the rows returned"
        where: notifications_bool_exp
    ): [notifications!]!
    "fetch aggregated fields from the table: \"notifications\""
    notifications_aggregate(
        "distinct select on columns"
        distinct_on: [notifications_select_column!],
        "limit the number of rows returned"
        limit: Int,
        "skip the first n rows. Use only with order_by"
        offset: Int,
        "sort the rows by one or more columns"
        order_by: [notifications_order_by!],
        "filter the rows returned"
        where: notifications_bool_exp
    ): notifications_aggregate!
    "fetch data from the table: \"notifications\" using primary key columns"
    notifications_by_pk(id: String!): notifications
    "fetch data from the table in a streaming manner: \"notifications\""
    notifications_stream(
        "maximum number of rows returned in a single batch"
        batch_size: Int!,
        "cursor to stream the results returned by the query"
        cursor: [notifications_stream_cursor_input]!,
        "filter the rows returned"
        where: notifications_bool_exp
    ): [notifications!]!
    "fetch data from the table: \"profile\""
    profile(
        "distinct select on columns"
        distinct_on: [profile_select_column!],
        "limit the number of rows returned"
        limit: Int,
        "skip the first n rows. Use only with order_by"
        offset: Int,
        "sort the rows by one or more columns"
        order_by: [profile_order_by!],
        "filter the rows returned"
        where: profile_bool_exp
    ): [profile!]!
    "fetch aggregated fields from the table: \"profile\""
    profile_aggregate(
        "distinct select on columns"
        distinct_on: [profile_select_column!],
        "limit the number of rows returned"
        limit: Int,
        "skip the first n rows. Use only with order_by"
        offset: Int,
        "sort the rows by one or more columns"
        order_by: [profile_order_by!],
        "filter the rows returned"
        where: profile_bool_exp
    ): profile_aggregate!
    "fetch data from the table: \"profile\" using primary key columns"
    profile_by_pk(address: String!): profile
    "fetch data from the table in a streaming manner: \"profile\""
    profile_stream(
        "maximum number of rows returned in a single batch"
        batch_size: Int!,
        "cursor to stream the results returned by the query"
        cursor: [profile_stream_cursor_input]!,
        "filter the rows returned"
        where: profile_bool_exp
    ): [profile!]!
    "fetch data from the table: \"user_contacts\""
    user_contacts(
        "distinct select on columns"
        distinct_on: [user_contacts_select_column!],
        "limit the number of rows returned"
        limit: Int,
        "skip the first n rows. Use only with order_by"
        offset: Int,
        "sort the rows by one or more columns"
        order_by: [user_contacts_order_by!],
        "filter the rows returned"
        where: user_contacts_bool_exp
    ): [user_contacts!]!
    "fetch aggregated fields from the table: \"user_contacts\""
    user_contacts_aggregate(
        "distinct select on columns"
        distinct_on: [user_contacts_select_column!],
        "limit the number of rows returned"
        limit: Int,
        "skip the first n rows. Use only with order_by"
        offset: Int,
        "sort the rows by one or more columns"
        order_by: [user_contacts_order_by!],
        "filter the rows returned"
        where: user_contacts_bool_exp
    ): user_contacts_aggregate!
    "fetch data from the table: \"user_contacts\" using primary key columns"
    user_contacts_by_pk(id: String!): user_contacts
    "fetch data from the table in a streaming manner: \"user_contacts\""
    user_contacts_stream(
        "maximum number of rows returned in a single batch"
        batch_size: Int!,
        "cursor to stream the results returned by the query"
        cursor: [user_contacts_stream_cursor_input]!,
        "filter the rows returned"
        where: user_contacts_bool_exp
    ): [user_contacts!]!
}

"columns and relationships of \"user_contacts\""
type user_contacts {
    creation_time: timestamptz!
    desmos_address: String!
    id: String!
    platform: String!
    "An array relationship"
    shared_contacts(
        "distinct select on columns"
        distinct_on: [bond_shared_contacts_select_column!],
        "limit the number of rows returned"
        limit: Int,
        "skip the first n rows. Use only with order_by"
        offset: Int,
        "sort the rows by one or more columns"
        order_by: [bond_shared_contacts_order_by!],
        "filter the rows returned"
        where: bond_shared_contacts_bool_exp
    ): [bond_shared_contacts!]!
    "An aggregate relationship"
    shared_contacts_aggregate(
        "distinct select on columns"
        distinct_on: [bond_shared_contacts_select_column!],
        "limit the number of rows returned"
        limit: Int,
        "skip the first n rows. Use only with order_by"
        offset: Int,
        "sort the rows by one or more columns"
        order_by: [bond_shared_contacts_order_by!],
        "filter the rows returned"
        where: bond_shared_contacts_bool_exp
    ): bond_shared_contacts_aggregate!
    username: String!
}

"aggregated selection of \"user_contacts\""
type user_contacts_aggregate {
    aggregate: user_contacts_aggregate_fields
    nodes: [user_contacts!]!
}

"aggregate fields of \"user_contacts\""
type user_contacts_aggregate_fields {
    count(columns: [user_contacts_select_column!], distinct: Boolean): Int!
    max: user_contacts_max_fields
    min: user_contacts_min_fields
}

"aggregate max on columns"
type user_contacts_max_fields {
    creation_time: timestamptz
    desmos_address: String
    id: String
    platform: String
    username: String
}

"aggregate min on columns"
type user_contacts_min_fields {
    creation_time: timestamptz
    desmos_address: String
    id: String
    platform: String
    username: String
}

"response of any mutation on the table \"user_contacts\""
type user_contacts_mutation_response {
    "number of rows affected by the mutation"
    affected_rows: Int!
    "data from the rows affected by the mutation"
    returning: [user_contacts!]!
}

"unique or primary key constraints on table \"bond_shared_contacts\""
enum bond_shared_contacts_constraint {
    "unique or primary key constraint on columns \"id\""
    bond_shared_contacts_pkey
    "unique or primary key constraint on columns \"bond_id\", \"contact_id\""
    unique_bond_shared_contact
}

"select columns of table \"bond_shared_contacts\""
enum bond_shared_contacts_select_column {
    "column name"
    bond_id
    "column name"
    contact_id
    "column name"
    id
}

"update columns of table \"bond_shared_contacts\""
enum bond_shared_contacts_update_column {
    "column name"
    bond_id
    "column name"
    contact_id
    "column name"
    id
}

"unique or primary key constraints on table \"bonds\""
enum bonds_constraint {
    "unique or primary key constraint on columns \"id\""
    bonds_pkey
    "unique or primary key constraint on columns \"counterparty_address\", \"creator_address\""
    unique_bond
}

"select columns of table \"bonds\""
enum bonds_select_column {
    "column name"
    counterparty_address
    "column name"
    counterparty_tx_hash
    "column name"
    creation_time
    "column name"
    creator_address
    "column name"
    creator_tx_hash
    "column name"
    event_id
    "column name"
    id
    "column name"
    photo_url
    "column name"
    status
}

"update columns of table \"bonds\""
enum bonds_update_column {
    "column name"
    counterparty_address
    "column name"
    counterparty_tx_hash
    "column name"
    creation_time
    "column name"
    creator_address
    "column name"
    creator_tx_hash
    "column name"
    event_id
    "column name"
    id
    "column name"
    photo_url
    "column name"
    status
}

"ordering argument of a cursor"
enum cursor_ordering {
    "ascending ordering of the cursor"
    ASC
    "descending ordering of the cursor"
    DESC
}

"unique or primary key constraints on table \"event_categories\""
enum event_categories_constraint {
    "unique or primary key constraint on columns \"id\""
    event_categories_pkey
}

"select columns of table \"event_categories\""
enum event_categories_select_column {
    "column name"
    category_id
    "column name"
    event_id
    "column name"
    id
}

"update columns of table \"event_categories\""
enum event_categories_update_column {
    "column name"
    category_id
    "column name"
    event_id
    "column name"
    id
}

"unique or primary key constraints on table \"event_likes\""
enum event_likes_constraint {
    "unique or primary key constraint on columns \"event_id\", \"liker_address\""
    event_likes_pkey
}

"select columns of table \"event_likes\""
enum event_likes_select_column {
    "column name"
    creation_time
    "column name"
    event_id
    "column name"
    liker_address
}

"update columns of table \"event_likes\""
enum event_likes_update_column {
    "column name"
    creation_time
    "column name"
    event_id
    "column name"
    liker_address
}

"unique or primary key constraints on table \"event_organizers\""
enum event_organizers_constraint {
    "unique or primary key constraint on columns \"id\""
    event_organizers_pkey
    "unique or primary key constraint on columns \"event_id\", \"organizer_address\""
    unique_event_organizer
}

"select columns of table \"event_organizers\""
enum event_organizers_select_column {
    "column name"
    event_id
    "column name"
    id
    "column name"
    organizer_address
}

"update columns of table \"event_organizers\""
enum event_organizers_update_column {
    "column name"
    event_id
    "column name"
    id
    "column name"
    organizer_address
}

"unique or primary key constraints on table \"event_participations\""
enum event_participations_constraint {
    "unique or primary key constraint on columns \"id\""
    event_participations_pkey
}

"select columns of table \"event_participations\""
enum event_participations_select_column {
    "column name"
    event_id
    "column name"
    id
    "column name"
    participant_address
    "column name"
    participation_end_time
    "column name"
    participation_start_time
}

"update columns of table \"event_participations\""
enum event_participations_update_column {
    "column name"
    event_id
    "column name"
    id
    "column name"
    participant_address
    "column name"
    participation_end_time
    "column name"
    participation_start_time
}

"select columns of table \"event_tags\""
enum event_tags_select_column {
    "column name"
    event_count
    "column name"
    tag
}

"unique or primary key constraints on table \"events_categories\""
enum events_categories_constraint {
    "unique or primary key constraint on columns \"id\""
    events_categories_pkey
}

"select columns of table \"events_categories\""
enum events_categories_select_column {
    "column name"
    id
    "column name"
    name
}

"update columns of table \"events_categories\""
enum events_categories_update_column {
    "column name"
    id
    "column name"
    name
}

"unique or primary key constraints on table \"events\""
enum events_constraint {
    "unique or primary key constraint on columns \"id\""
    events_pkey
}

"select columns of table \"events\""
enum events_select_column {
    "column name"
    cover_picture_url
    "column name"
    description
    "column name"
    details_link
    "column name"
    end_date
    "column name"
    google_place_id
    "column name"
    id
    "column name"
    join_code
    "column name"
    join_link
    "column name"
    location_administrative_area_level_1
    "column name"
    location_administrative_area_level_2
    "column name"
    location_administrative_area_level_3
    "column name"
    location_coordinates
    "column name"
    location_country
    "column name"
    location_formatted_address
    "column name"
    location_locality
    "column name"
    name
    "column name"
    start_date
    "column name"
    tags
    "column name"
    website
}

"update columns of table \"events\""
enum events_update_column {
    "column name"
    cover_picture_url
    "column name"
    description
    "column name"
    details_link
    "column name"
    end_date
    "column name"
    google_place_id
    "column name"
    id
    "column name"
    join_code
    "column name"
    join_link
    "column name"
    location_administrative_area_level_1
    "column name"
    location_administrative_area_level_2
    "column name"
    location_administrative_area_level_3
    "column name"
    location_coordinates
    "column name"
    location_country
    "column name"
    location_formatted_address
    "column name"
    location_locality
    "column name"
    name
    "column name"
    start_date
    "column name"
    tags
    "column name"
    website
}

"unique or primary key constraints on table \"images_hashes\""
enum images_hashes_constraint {
    "unique or primary key constraint on columns \"image_url\""
    images_hashes_pkey
}

"select columns of table \"images_hashes\""
enum images_hashes_select_column {
    "column name"
    hash
    "column name"
    image_url
}

"update columns of table \"images_hashes\""
enum images_hashes_update_column {
    "column name"
    hash
    "column name"
    image_url
}

"unique or primary key constraints on table \"memories\""
enum memories_constraint {
    "unique or primary key constraint on columns \"id\""
    memories_pkey
}

"select columns of table \"memories\""
enum memories_select_column {
    "column name"
    creation_time
    "column name"
    creator_address
    "column name"
    details_link
    "column name"
    event_id
    "column name"
    id
    "column name"
    image_url
}

"update columns of table \"memories\""
enum memories_update_column {
    "column name"
    creation_time
    "column name"
    creator_address
    "column name"
    details_link
    "column name"
    event_id
    "column name"
    id
    "column name"
    image_url
}

"unique or primary key constraints on table \"memory_likes\""
enum memory_likes_constraint {
    "unique or primary key constraint on columns \"liker_address\", \"memory_id\""
    memory_likes_pkey
}

"select columns of table \"memory_likes\""
enum memory_likes_select_column {
    "column name"
    creation_time
    "column name"
    liker_address
    "column name"
    memory_id
}

"update columns of table \"memory_likes\""
enum memory_likes_update_column {
    "column name"
    creation_time
    "column name"
    liker_address
    "column name"
    memory_id
}

"unique or primary key constraints on table \"notifications\""
enum notifications_constraint {
    "unique or primary key constraint on columns \"id\""
    notifications_pkey
}

"select columns of table \"notifications\""
enum notifications_select_column {
    "column name"
    additional_data
    "column name"
    body
    "column name"
    id
    "column name"
    image_url
    "column name"
    timestamp
    "column name"
    title
    "column name"
    type
    "column name"
    user_address
}

"update columns of table \"notifications\""
enum notifications_update_column {
    "column name"
    additional_data
    "column name"
    body
    "column name"
    id
    "column name"
    image_url
    "column name"
    timestamp
    "column name"
    title
    "column name"
    type
    "column name"
    user_address
}

"column ordering options"
enum order_by {
    "in ascending order, nulls last"
    asc
    "in ascending order, nulls first"
    asc_nulls_first
    "in ascending order, nulls last"
    asc_nulls_last
    "in descending order, nulls first"
    desc
    "in descending order, nulls first"
    desc_nulls_first
    "in descending order, nulls last"
    desc_nulls_last
}

"unique or primary key constraints on table \"profile\""
enum profile_constraint {
    "unique or primary key constraint on columns \"address\""
    profile_pkey
}

"select columns of table \"profile\""
enum profile_select_column {
    "column name"
    address
    "column name"
    bio
    "column name"
    cover_pic
    "column name"
    creation_time
    "column name"
    dtag
    "column name"
    height
    "column name"
    nickname
    "column name"
    profile_pic
}

"update columns of table \"profile\""
enum profile_update_column {
    "column name"
    address
    "column name"
    bio
    "column name"
    cover_pic
    "column name"
    creation_time
    "column name"
    dtag
    "column name"
    height
    "column name"
    nickname
    "column name"
    profile_pic
}

"unique or primary key constraints on table \"user_contacts\""
enum user_contacts_constraint {
    "unique or primary key constraint on columns \"platform\", \"desmos_address\""
    unique_platform_user_contact
    "unique or primary key constraint on columns \"id\""
    user_contacts_pkey
}

"select columns of table \"user_contacts\""
enum user_contacts_select_column {
    "column name"
    creation_time
    "column name"
    desmos_address
    "column name"
    id
    "column name"
    platform
    "column name"
    username
}

"update columns of table \"user_contacts\""
enum user_contacts_update_column {
    "column name"
    creation_time
    "column name"
    desmos_address
    "column name"
    id
    "column name"
    platform
    "column name"
    username
}

scalar bigint

scalar bond_status

scalar geography

scalar geometry

scalar jsonb

scalar timestamp

scalar timestamptz

"Boolean expression to compare columns of type \"Boolean\". All fields are combined with logical 'AND'."
input Boolean_comparison_exp {
    _eq: Boolean
    _gt: Boolean
    _gte: Boolean
    _in: [Boolean!]
    _is_null: Boolean
    _lt: Boolean
    _lte: Boolean
    _neq: Boolean
    _nin: [Boolean!]
}

"Boolean expression to compare columns of type \"Int\". All fields are combined with logical 'AND'."
input Int_comparison_exp {
    _eq: Int
    _gt: Int
    _gte: Int
    _in: [Int!]
    _is_null: Boolean
    _lt: Int
    _lte: Int
    _neq: Int
    _nin: [Int!]
}

"Boolean expression to compare columns of type \"String\". All fields are combined with logical 'AND'."
input String_comparison_exp {
    _eq: String
    _gt: String
    _gte: String
    "does the column match the given case-insensitive pattern"
    _ilike: String
    _in: [String!]
    "does the column match the given POSIX regular expression, case insensitive"
    _iregex: String
    _is_null: Boolean
    "does the column match the given pattern"
    _like: String
    _lt: String
    _lte: String
    _neq: String
    "does the column NOT match the given case-insensitive pattern"
    _nilike: String
    _nin: [String!]
    "does the column NOT match the given POSIX regular expression, case insensitive"
    _niregex: String
    "does the column NOT match the given pattern"
    _nlike: String
    "does the column NOT match the given POSIX regular expression, case sensitive"
    _nregex: String
    "does the column NOT match the given SQL regular expression"
    _nsimilar: String
    "does the column match the given POSIX regular expression, case sensitive"
    _regex: String
    "does the column match the given SQL regular expression"
    _similar: String
}

"Boolean expression to compare columns of type \"bigint\". All fields are combined with logical 'AND'."
input bigint_comparison_exp {
    _eq: bigint
    _gt: bigint
    _gte: bigint
    _in: [bigint!]
    _is_null: Boolean
    _lt: bigint
    _lte: bigint
    _neq: bigint
    _nin: [bigint!]
}

input bond_shared_contacts_aggregate_bool_exp {
    count: bond_shared_contacts_aggregate_bool_exp_count
}

input bond_shared_contacts_aggregate_bool_exp_count {
    arguments: [bond_shared_contacts_select_column!]
    distinct: Boolean
    filter: bond_shared_contacts_bool_exp
    predicate: Int_comparison_exp!
}

"order by aggregate values of table \"bond_shared_contacts\""
input bond_shared_contacts_aggregate_order_by {
    count: order_by
    max: bond_shared_contacts_max_order_by
    min: bond_shared_contacts_min_order_by
}

"input type for inserting array relation for remote table \"bond_shared_contacts\""
input bond_shared_contacts_arr_rel_insert_input {
    data: [bond_shared_contacts_insert_input!]!
    "upsert condition"
    on_conflict: bond_shared_contacts_on_conflict
}

"Boolean expression to filter rows from the table \"bond_shared_contacts\". All fields are combined with a logical 'AND'."
input bond_shared_contacts_bool_exp {
    _and: [bond_shared_contacts_bool_exp!]
    _not: bond_shared_contacts_bool_exp
    _or: [bond_shared_contacts_bool_exp!]
    bond: bonds_bool_exp
    bond_id: String_comparison_exp
    contact: user_contacts_bool_exp
    contact_id: String_comparison_exp
    id: String_comparison_exp
}

"input type for inserting data into table \"bond_shared_contacts\""
input bond_shared_contacts_insert_input {
    bond: bonds_obj_rel_insert_input
    bond_id: String
    contact: user_contacts_obj_rel_insert_input
    contact_id: String
    id: String
}

"order by max() on columns of table \"bond_shared_contacts\""
input bond_shared_contacts_max_order_by {
    bond_id: order_by
    contact_id: order_by
    id: order_by
}

"order by min() on columns of table \"bond_shared_contacts\""
input bond_shared_contacts_min_order_by {
    bond_id: order_by
    contact_id: order_by
    id: order_by
}

"on_conflict condition type for table \"bond_shared_contacts\""
input bond_shared_contacts_on_conflict {
    constraint: bond_shared_contacts_constraint!
    update_columns: [bond_shared_contacts_update_column!]! = []
    where: bond_shared_contacts_bool_exp
}

"Ordering options when selecting data from \"bond_shared_contacts\"."
input bond_shared_contacts_order_by {
    bond: bonds_order_by
    bond_id: order_by
    contact: user_contacts_order_by
    contact_id: order_by
    id: order_by
}

"primary key columns input for table: bond_shared_contacts"
input bond_shared_contacts_pk_columns_input {
    id: String!
}

"input type for updating data in table \"bond_shared_contacts\""
input bond_shared_contacts_set_input {
    bond_id: String
    contact_id: String
    id: String
}

"Streaming cursor of the table \"bond_shared_contacts\""
input bond_shared_contacts_stream_cursor_input {
    "Stream column input with initial value"
    initial_value: bond_shared_contacts_stream_cursor_value_input!
    "cursor ordering"
    ordering: cursor_ordering
}

"Initial value of the column from where the streaming should start"
input bond_shared_contacts_stream_cursor_value_input {
    bond_id: String
    contact_id: String
    id: String
}

input bond_shared_contacts_updates {
    "sets the columns of the filtered rows to the given values"
    _set: bond_shared_contacts_set_input
    "filter the rows which have to be updated"
    where: bond_shared_contacts_bool_exp!
}

"Boolean expression to compare columns of type \"bond_status\". All fields are combined with logical 'AND'."
input bond_status_comparison_exp {
    _eq: bond_status
    _gt: bond_status
    _gte: bond_status
    _in: [bond_status!]
    _is_null: Boolean
    _lt: bond_status
    _lte: bond_status
    _neq: bond_status
    _nin: [bond_status!]
}

input bonds_aggregate_bool_exp {
    count: bonds_aggregate_bool_exp_count
}

input bonds_aggregate_bool_exp_count {
    arguments: [bonds_select_column!]
    distinct: Boolean
    filter: bonds_bool_exp
    predicate: Int_comparison_exp!
}

"order by aggregate values of table \"bonds\""
input bonds_aggregate_order_by {
    count: order_by
    max: bonds_max_order_by
    min: bonds_min_order_by
}

"input type for inserting array relation for remote table \"bonds\""
input bonds_arr_rel_insert_input {
    data: [bonds_insert_input!]!
    "upsert condition"
    on_conflict: bonds_on_conflict
}

"Boolean expression to filter rows from the table \"bonds\". All fields are combined with a logical 'AND'."
input bonds_bool_exp {
    _and: [bonds_bool_exp!]
    _not: bonds_bool_exp
    _or: [bonds_bool_exp!]
    counterparty_address: String_comparison_exp
    counterparty_tx_hash: String_comparison_exp
    creation_time: timestamptz_comparison_exp
    creator_address: String_comparison_exp
    creator_tx_hash: String_comparison_exp
    event: events_bool_exp
    event_id: String_comparison_exp
    id: String_comparison_exp
    photo_hash: images_hashes_bool_exp
    photo_url: String_comparison_exp
    shared_contacts: bond_shared_contacts_bool_exp
    shared_contacts_aggregate: bond_shared_contacts_aggregate_bool_exp
    status: bond_status_comparison_exp
}

"input type for inserting data into table \"bonds\""
input bonds_insert_input {
    counterparty_address: String
    counterparty_tx_hash: String
    creation_time: timestamptz
    creator_address: String
    creator_tx_hash: String
    event: events_obj_rel_insert_input
    event_id: String
    id: String
    photo_hash: images_hashes_obj_rel_insert_input
    photo_url: String
    shared_contacts: bond_shared_contacts_arr_rel_insert_input
    status: bond_status
}

"order by max() on columns of table \"bonds\""
input bonds_max_order_by {
    counterparty_address: order_by
    counterparty_tx_hash: order_by
    creation_time: order_by
    creator_address: order_by
    creator_tx_hash: order_by
    event_id: order_by
    id: order_by
    photo_url: order_by
    status: order_by
}

"order by min() on columns of table \"bonds\""
input bonds_min_order_by {
    counterparty_address: order_by
    counterparty_tx_hash: order_by
    creation_time: order_by
    creator_address: order_by
    creator_tx_hash: order_by
    event_id: order_by
    id: order_by
    photo_url: order_by
    status: order_by
}

"input type for inserting object relation for remote table \"bonds\""
input bonds_obj_rel_insert_input {
    data: bonds_insert_input!
    "upsert condition"
    on_conflict: bonds_on_conflict
}

"on_conflict condition type for table \"bonds\""
input bonds_on_conflict {
    constraint: bonds_constraint!
    update_columns: [bonds_update_column!]! = []
    where: bonds_bool_exp
}

"Ordering options when selecting data from \"bonds\"."
input bonds_order_by {
    counterparty_address: order_by
    counterparty_tx_hash: order_by
    creation_time: order_by
    creator_address: order_by
    creator_tx_hash: order_by
    event: events_order_by
    event_id: order_by
    id: order_by
    photo_hash: images_hashes_order_by
    photo_url: order_by
    shared_contacts_aggregate: bond_shared_contacts_aggregate_order_by
    status: order_by
}

"primary key columns input for table: bonds"
input bonds_pk_columns_input {
    id: String!
}

"input type for updating data in table \"bonds\""
input bonds_set_input {
    counterparty_address: String
    counterparty_tx_hash: String
    creation_time: timestamptz
    creator_address: String
    creator_tx_hash: String
    event_id: String
    id: String
    photo_url: String
    status: bond_status
}

"Streaming cursor of the table \"bonds\""
input bonds_stream_cursor_input {
    "Stream column input with initial value"
    initial_value: bonds_stream_cursor_value_input!
    "cursor ordering"
    ordering: cursor_ordering
}

"Initial value of the column from where the streaming should start"
input bonds_stream_cursor_value_input {
    counterparty_address: String
    counterparty_tx_hash: String
    creation_time: timestamptz
    creator_address: String
    creator_tx_hash: String
    event_id: String
    id: String
    photo_url: String
    status: bond_status
}

input bonds_updates {
    "sets the columns of the filtered rows to the given values"
    _set: bonds_set_input
    "filter the rows which have to be updated"
    where: bonds_bool_exp!
}

"Boolean expression to filter rows from the table \"event_categories\". All fields are combined with a logical 'AND'."
input event_categories_bool_exp {
    _and: [event_categories_bool_exp!]
    _not: event_categories_bool_exp
    _or: [event_categories_bool_exp!]
    category_id: Int_comparison_exp
    event_id: String_comparison_exp
    id: Int_comparison_exp
}

"input type for incrementing numeric columns in table \"event_categories\""
input event_categories_inc_input {
    category_id: Int
    id: Int
}

"input type for inserting data into table \"event_categories\""
input event_categories_insert_input {
    category_id: Int
    event_id: String
    id: Int
}

"on_conflict condition type for table \"event_categories\""
input event_categories_on_conflict {
    constraint: event_categories_constraint!
    update_columns: [event_categories_update_column!]! = []
    where: event_categories_bool_exp
}

"Ordering options when selecting data from \"event_categories\"."
input event_categories_order_by {
    category_id: order_by
    event_id: order_by
    id: order_by
}

"primary key columns input for table: event_categories"
input event_categories_pk_columns_input {
    id: Int!
}

"input type for updating data in table \"event_categories\""
input event_categories_set_input {
    category_id: Int
    event_id: String
    id: Int
}

"Streaming cursor of the table \"event_categories\""
input event_categories_stream_cursor_input {
    "Stream column input with initial value"
    initial_value: event_categories_stream_cursor_value_input!
    "cursor ordering"
    ordering: cursor_ordering
}

"Initial value of the column from where the streaming should start"
input event_categories_stream_cursor_value_input {
    category_id: Int
    event_id: String
    id: Int
}

input event_categories_updates {
    "increments the numeric columns with given value of the filtered values"
    _inc: event_categories_inc_input
    "sets the columns of the filtered rows to the given values"
    _set: event_categories_set_input
    "filter the rows which have to be updated"
    where: event_categories_bool_exp!
}

input event_likes_aggregate_bool_exp {
    count: event_likes_aggregate_bool_exp_count
}

input event_likes_aggregate_bool_exp_count {
    arguments: [event_likes_select_column!]
    distinct: Boolean
    filter: event_likes_bool_exp
    predicate: Int_comparison_exp!
}

"order by aggregate values of table \"event_likes\""
input event_likes_aggregate_order_by {
    count: order_by
    max: event_likes_max_order_by
    min: event_likes_min_order_by
}

"input type for inserting array relation for remote table \"event_likes\""
input event_likes_arr_rel_insert_input {
    data: [event_likes_insert_input!]!
    "upsert condition"
    on_conflict: event_likes_on_conflict
}

"Boolean expression to filter rows from the table \"event_likes\". All fields are combined with a logical 'AND'."
input event_likes_bool_exp {
    _and: [event_likes_bool_exp!]
    _not: event_likes_bool_exp
    _or: [event_likes_bool_exp!]
    creation_time: timestamptz_comparison_exp
    event: events_bool_exp
    event_id: String_comparison_exp
    liker_address: String_comparison_exp
}

"input type for inserting data into table \"event_likes\""
input event_likes_insert_input {
    creation_time: timestamptz
    event: events_obj_rel_insert_input
    event_id: String
    liker_address: String
}

"order by max() on columns of table \"event_likes\""
input event_likes_max_order_by {
    creation_time: order_by
    event_id: order_by
    liker_address: order_by
}

"order by min() on columns of table \"event_likes\""
input event_likes_min_order_by {
    creation_time: order_by
    event_id: order_by
    liker_address: order_by
}

"on_conflict condition type for table \"event_likes\""
input event_likes_on_conflict {
    constraint: event_likes_constraint!
    update_columns: [event_likes_update_column!]! = []
    where: event_likes_bool_exp
}

"Ordering options when selecting data from \"event_likes\"."
input event_likes_order_by {
    creation_time: order_by
    event: events_order_by
    event_id: order_by
    liker_address: order_by
}

"primary key columns input for table: event_likes"
input event_likes_pk_columns_input {
    event_id: String!
    liker_address: String!
}

"input type for updating data in table \"event_likes\""
input event_likes_set_input {
    creation_time: timestamptz
    event_id: String
    liker_address: String
}

"Streaming cursor of the table \"event_likes\""
input event_likes_stream_cursor_input {
    "Stream column input with initial value"
    initial_value: event_likes_stream_cursor_value_input!
    "cursor ordering"
    ordering: cursor_ordering
}

"Initial value of the column from where the streaming should start"
input event_likes_stream_cursor_value_input {
    creation_time: timestamptz
    event_id: String
    liker_address: String
}

input event_likes_updates {
    "sets the columns of the filtered rows to the given values"
    _set: event_likes_set_input
    "filter the rows which have to be updated"
    where: event_likes_bool_exp!
}

input event_organizers_aggregate_bool_exp {
    count: event_organizers_aggregate_bool_exp_count
}

input event_organizers_aggregate_bool_exp_count {
    arguments: [event_organizers_select_column!]
    distinct: Boolean
    filter: event_organizers_bool_exp
    predicate: Int_comparison_exp!
}

"order by aggregate values of table \"event_organizers\""
input event_organizers_aggregate_order_by {
    avg: event_organizers_avg_order_by
    count: order_by
    max: event_organizers_max_order_by
    min: event_organizers_min_order_by
    stddev: event_organizers_stddev_order_by
    stddev_pop: event_organizers_stddev_pop_order_by
    stddev_samp: event_organizers_stddev_samp_order_by
    sum: event_organizers_sum_order_by
    var_pop: event_organizers_var_pop_order_by
    var_samp: event_organizers_var_samp_order_by
    variance: event_organizers_variance_order_by
}

"input type for inserting array relation for remote table \"event_organizers\""
input event_organizers_arr_rel_insert_input {
    data: [event_organizers_insert_input!]!
    "upsert condition"
    on_conflict: event_organizers_on_conflict
}

"order by avg() on columns of table \"event_organizers\""
input event_organizers_avg_order_by {
    id: order_by
}

"Boolean expression to filter rows from the table \"event_organizers\". All fields are combined with a logical 'AND'."
input event_organizers_bool_exp {
    _and: [event_organizers_bool_exp!]
    _not: event_organizers_bool_exp
    _or: [event_organizers_bool_exp!]
    event: events_bool_exp
    event_id: String_comparison_exp
    id: Int_comparison_exp
    organizer_address: String_comparison_exp
}

"input type for incrementing numeric columns in table \"event_organizers\""
input event_organizers_inc_input {
    id: Int
}

"input type for inserting data into table \"event_organizers\""
input event_organizers_insert_input {
    event: events_obj_rel_insert_input
    event_id: String
    id: Int
    organizer_address: String
}

"order by max() on columns of table \"event_organizers\""
input event_organizers_max_order_by {
    event_id: order_by
    id: order_by
    organizer_address: order_by
}

"order by min() on columns of table \"event_organizers\""
input event_organizers_min_order_by {
    event_id: order_by
    id: order_by
    organizer_address: order_by
}

"on_conflict condition type for table \"event_organizers\""
input event_organizers_on_conflict {
    constraint: event_organizers_constraint!
    update_columns: [event_organizers_update_column!]! = []
    where: event_organizers_bool_exp
}

"Ordering options when selecting data from \"event_organizers\"."
input event_organizers_order_by {
    event: events_order_by
    event_id: order_by
    id: order_by
    organizer_address: order_by
}

"primary key columns input for table: event_organizers"
input event_organizers_pk_columns_input {
    id: Int!
}

"input type for updating data in table \"event_organizers\""
input event_organizers_set_input {
    event_id: String
    id: Int
    organizer_address: String
}

"order by stddev() on columns of table \"event_organizers\""
input event_organizers_stddev_order_by {
    id: order_by
}

"order by stddev_pop() on columns of table \"event_organizers\""
input event_organizers_stddev_pop_order_by {
    id: order_by
}

"order by stddev_samp() on columns of table \"event_organizers\""
input event_organizers_stddev_samp_order_by {
    id: order_by
}

"Streaming cursor of the table \"event_organizers\""
input event_organizers_stream_cursor_input {
    "Stream column input with initial value"
    initial_value: event_organizers_stream_cursor_value_input!
    "cursor ordering"
    ordering: cursor_ordering
}

"Initial value of the column from where the streaming should start"
input event_organizers_stream_cursor_value_input {
    event_id: String
    id: Int
    organizer_address: String
}

"order by sum() on columns of table \"event_organizers\""
input event_organizers_sum_order_by {
    id: order_by
}

input event_organizers_updates {
    "increments the numeric columns with given value of the filtered values"
    _inc: event_organizers_inc_input
    "sets the columns of the filtered rows to the given values"
    _set: event_organizers_set_input
    "filter the rows which have to be updated"
    where: event_organizers_bool_exp!
}

"order by var_pop() on columns of table \"event_organizers\""
input event_organizers_var_pop_order_by {
    id: order_by
}

"order by var_samp() on columns of table \"event_organizers\""
input event_organizers_var_samp_order_by {
    id: order_by
}

"order by variance() on columns of table \"event_organizers\""
input event_organizers_variance_order_by {
    id: order_by
}

input event_participations_aggregate_bool_exp {
    count: event_participations_aggregate_bool_exp_count
}

input event_participations_aggregate_bool_exp_count {
    arguments: [event_participations_select_column!]
    distinct: Boolean
    filter: event_participations_bool_exp
    predicate: Int_comparison_exp!
}

"order by aggregate values of table \"event_participations\""
input event_participations_aggregate_order_by {
    avg: event_participations_avg_order_by
    count: order_by
    max: event_participations_max_order_by
    min: event_participations_min_order_by
    stddev: event_participations_stddev_order_by
    stddev_pop: event_participations_stddev_pop_order_by
    stddev_samp: event_participations_stddev_samp_order_by
    sum: event_participations_sum_order_by
    var_pop: event_participations_var_pop_order_by
    var_samp: event_participations_var_samp_order_by
    variance: event_participations_variance_order_by
}

"input type for inserting array relation for remote table \"event_participations\""
input event_participations_arr_rel_insert_input {
    data: [event_participations_insert_input!]!
    "upsert condition"
    on_conflict: event_participations_on_conflict
}

"order by avg() on columns of table \"event_participations\""
input event_participations_avg_order_by {
    id: order_by
}

"Boolean expression to filter rows from the table \"event_participations\". All fields are combined with a logical 'AND'."
input event_participations_bool_exp {
    _and: [event_participations_bool_exp!]
    _not: event_participations_bool_exp
    _or: [event_participations_bool_exp!]
    event: events_bool_exp
    event_id: String_comparison_exp
    id: Int_comparison_exp
    participant_address: String_comparison_exp
    participation_end_time: timestamptz_comparison_exp
    participation_start_time: timestamptz_comparison_exp
}

"input type for incrementing numeric columns in table \"event_participations\""
input event_participations_inc_input {
    id: Int
}

"input type for inserting data into table \"event_participations\""
input event_participations_insert_input {
    event: events_obj_rel_insert_input
    event_id: String
    id: Int
    participant_address: String
    participation_end_time: timestamptz
    participation_start_time: timestamptz
}

"order by max() on columns of table \"event_participations\""
input event_participations_max_order_by {
    event_id: order_by
    id: order_by
    participant_address: order_by
    participation_end_time: order_by
    participation_start_time: order_by
}

"order by min() on columns of table \"event_participations\""
input event_participations_min_order_by {
    event_id: order_by
    id: order_by
    participant_address: order_by
    participation_end_time: order_by
    participation_start_time: order_by
}

"on_conflict condition type for table \"event_participations\""
input event_participations_on_conflict {
    constraint: event_participations_constraint!
    update_columns: [event_participations_update_column!]! = []
    where: event_participations_bool_exp
}

"Ordering options when selecting data from \"event_participations\"."
input event_participations_order_by {
    event: events_order_by
    event_id: order_by
    id: order_by
    participant_address: order_by
    participation_end_time: order_by
    participation_start_time: order_by
}

"primary key columns input for table: event_participations"
input event_participations_pk_columns_input {
    id: Int!
}

"input type for updating data in table \"event_participations\""
input event_participations_set_input {
    event_id: String
    id: Int
    participant_address: String
    participation_end_time: timestamptz
    participation_start_time: timestamptz
}

"order by stddev() on columns of table \"event_participations\""
input event_participations_stddev_order_by {
    id: order_by
}

"order by stddev_pop() on columns of table \"event_participations\""
input event_participations_stddev_pop_order_by {
    id: order_by
}

"order by stddev_samp() on columns of table \"event_participations\""
input event_participations_stddev_samp_order_by {
    id: order_by
}

"Streaming cursor of the table \"event_participations\""
input event_participations_stream_cursor_input {
    "Stream column input with initial value"
    initial_value: event_participations_stream_cursor_value_input!
    "cursor ordering"
    ordering: cursor_ordering
}

"Initial value of the column from where the streaming should start"
input event_participations_stream_cursor_value_input {
    event_id: String
    id: Int
    participant_address: String
    participation_end_time: timestamptz
    participation_start_time: timestamptz
}

"order by sum() on columns of table \"event_participations\""
input event_participations_sum_order_by {
    id: order_by
}

input event_participations_updates {
    "increments the numeric columns with given value of the filtered values"
    _inc: event_participations_inc_input
    "sets the columns of the filtered rows to the given values"
    _set: event_participations_set_input
    "filter the rows which have to be updated"
    where: event_participations_bool_exp!
}

"order by var_pop() on columns of table \"event_participations\""
input event_participations_var_pop_order_by {
    id: order_by
}

"order by var_samp() on columns of table \"event_participations\""
input event_participations_var_samp_order_by {
    id: order_by
}

"order by variance() on columns of table \"event_participations\""
input event_participations_variance_order_by {
    id: order_by
}

"Boolean expression to filter rows from the table \"event_tags\". All fields are combined with a logical 'AND'."
input event_tags_bool_exp {
    _and: [event_tags_bool_exp!]
    _not: event_tags_bool_exp
    _or: [event_tags_bool_exp!]
    event_count: bigint_comparison_exp
    tag: String_comparison_exp
}

"Ordering options when selecting data from \"event_tags\"."
input event_tags_order_by {
    event_count: order_by
    tag: order_by
}

"Streaming cursor of the table \"event_tags\""
input event_tags_stream_cursor_input {
    "Stream column input with initial value"
    initial_value: event_tags_stream_cursor_value_input!
    "cursor ordering"
    ordering: cursor_ordering
}

"Initial value of the column from where the streaming should start"
input event_tags_stream_cursor_value_input {
    event_count: bigint
    tag: String
}

"append existing jsonb value of filtered columns with new jsonb value"
input events_append_input {
    tags: jsonb
}

"Boolean expression to filter rows from the table \"events\". All fields are combined with a logical 'AND'."
input events_bool_exp {
    _and: [events_bool_exp!]
    _not: events_bool_exp
    _or: [events_bool_exp!]
    bonds: bonds_bool_exp
    bonds_aggregate: bonds_aggregate_bool_exp
    cover_picture_hash: images_hashes_bool_exp
    cover_picture_url: String_comparison_exp
    description: String_comparison_exp
    details_link: String_comparison_exp
    end_date: timestamptz_comparison_exp
    google_place_id: String_comparison_exp
    id: String_comparison_exp
    is_user_participating: Boolean_comparison_exp
    join_code: String_comparison_exp
    join_link: String_comparison_exp
    likes: event_likes_bool_exp
    likes_aggregate: event_likes_aggregate_bool_exp
    likes_count: bigint_comparison_exp
    location_administrative_area_level_1: String_comparison_exp
    location_administrative_area_level_2: String_comparison_exp
    location_administrative_area_level_3: String_comparison_exp
    location_coordinates: geography_comparison_exp
    location_country: String_comparison_exp
    location_formatted_address: String_comparison_exp
    location_locality: String_comparison_exp
    memories: memories_bool_exp
    memories_aggregate: memories_aggregate_bool_exp
    name: String_comparison_exp
    organizers: event_organizers_bool_exp
    organizers_aggregate: event_organizers_aggregate_bool_exp
    participants_count: bigint_comparison_exp
    participations: event_participations_bool_exp
    participations_aggregate: event_participations_aggregate_bool_exp
    start_date: timestamptz_comparison_exp
    tags: jsonb_comparison_exp
    website: String_comparison_exp
}

"Boolean expression to filter rows from the table \"events_categories\". All fields are combined with a logical 'AND'."
input events_categories_bool_exp {
    _and: [events_categories_bool_exp!]
    _not: events_categories_bool_exp
    _or: [events_categories_bool_exp!]
    id: Int_comparison_exp
    name: String_comparison_exp
}

"input type for incrementing numeric columns in table \"events_categories\""
input events_categories_inc_input {
    id: Int
}

"input type for inserting data into table \"events_categories\""
input events_categories_insert_input {
    id: Int
    name: String
}

"on_conflict condition type for table \"events_categories\""
input events_categories_on_conflict {
    constraint: events_categories_constraint!
    update_columns: [events_categories_update_column!]! = []
    where: events_categories_bool_exp
}

"Ordering options when selecting data from \"events_categories\"."
input events_categories_order_by {
    id: order_by
    name: order_by
}

"primary key columns input for table: events_categories"
input events_categories_pk_columns_input {
    id: Int!
}

"input type for updating data in table \"events_categories\""
input events_categories_set_input {
    id: Int
    name: String
}

"Streaming cursor of the table \"events_categories\""
input events_categories_stream_cursor_input {
    "Stream column input with initial value"
    initial_value: events_categories_stream_cursor_value_input!
    "cursor ordering"
    ordering: cursor_ordering
}

"Initial value of the column from where the streaming should start"
input events_categories_stream_cursor_value_input {
    id: Int
    name: String
}

input events_categories_updates {
    "increments the numeric columns with given value of the filtered values"
    _inc: events_categories_inc_input
    "sets the columns of the filtered rows to the given values"
    _set: events_categories_set_input
    "filter the rows which have to be updated"
    where: events_categories_bool_exp!
}

"delete the field or element with specified path (for JSON arrays, negative integers count from the end)"
input events_delete_at_path_input {
    tags: [String!]
}

"delete the array element with specified index (negative integers count from the end). throws an error if top level container is not an array"
input events_delete_elem_input {
    tags: Int
}

"delete key/value pair or string element. key/value pairs are matched based on their key value"
input events_delete_key_input {
    tags: String
}

"input type for inserting data into table \"events\""
input events_insert_input {
    bonds: bonds_arr_rel_insert_input
    cover_picture_hash: images_hashes_obj_rel_insert_input
    cover_picture_url: String
    description: String
    details_link: String
    end_date: timestamptz
    google_place_id: String
    id: String
    join_code: String
    join_link: String
    likes: event_likes_arr_rel_insert_input
    location_administrative_area_level_1: String
    location_administrative_area_level_2: String
    location_administrative_area_level_3: String
    location_coordinates: geography
    location_country: String
    location_formatted_address: String
    location_locality: String
    memories: memories_arr_rel_insert_input
    name: String
    organizers: event_organizers_arr_rel_insert_input
    participations: event_participations_arr_rel_insert_input
    start_date: timestamptz
    tags: jsonb
    website: String
}

"input type for inserting object relation for remote table \"events\""
input events_obj_rel_insert_input {
    data: events_insert_input!
    "upsert condition"
    on_conflict: events_on_conflict
}

"on_conflict condition type for table \"events\""
input events_on_conflict {
    constraint: events_constraint!
    update_columns: [events_update_column!]! = []
    where: events_bool_exp
}

"Ordering options when selecting data from \"events\"."
input events_order_by {
    bonds_aggregate: bonds_aggregate_order_by
    cover_picture_hash: images_hashes_order_by
    cover_picture_url: order_by
    description: order_by
    details_link: order_by
    end_date: order_by
    google_place_id: order_by
    id: order_by
    is_user_participating: order_by
    join_code: order_by
    join_link: order_by
    likes_aggregate: event_likes_aggregate_order_by
    likes_count: order_by
    location_administrative_area_level_1: order_by
    location_administrative_area_level_2: order_by
    location_administrative_area_level_3: order_by
    location_coordinates: order_by
    location_country: order_by
    location_formatted_address: order_by
    location_locality: order_by
    memories_aggregate: memories_aggregate_order_by
    name: order_by
    organizers_aggregate: event_organizers_aggregate_order_by
    participants_count: order_by
    participations_aggregate: event_participations_aggregate_order_by
    start_date: order_by
    tags: order_by
    website: order_by
}

"primary key columns input for table: events"
input events_pk_columns_input {
    id: String!
}

"prepend existing jsonb value of filtered columns with new jsonb value"
input events_prepend_input {
    tags: jsonb
}

"input type for updating data in table \"events\""
input events_set_input {
    cover_picture_url: String
    description: String
    details_link: String
    end_date: timestamptz
    google_place_id: String
    id: String
    join_code: String
    join_link: String
    location_administrative_area_level_1: String
    location_administrative_area_level_2: String
    location_administrative_area_level_3: String
    location_coordinates: geography
    location_country: String
    location_formatted_address: String
    location_locality: String
    name: String
    start_date: timestamptz
    tags: jsonb
    website: String
}

"Streaming cursor of the table \"events\""
input events_stream_cursor_input {
    "Stream column input with initial value"
    initial_value: events_stream_cursor_value_input!
    "cursor ordering"
    ordering: cursor_ordering
}

"Initial value of the column from where the streaming should start"
input events_stream_cursor_value_input {
    cover_picture_url: String
    description: String
    details_link: String
    end_date: timestamptz
    google_place_id: String
    id: String
    join_code: String
    join_link: String
    location_administrative_area_level_1: String
    location_administrative_area_level_2: String
    location_administrative_area_level_3: String
    location_coordinates: geography
    location_country: String
    location_formatted_address: String
    location_locality: String
    name: String
    start_date: timestamptz
    tags: jsonb
    website: String
}

input events_updates {
    "append existing jsonb value of filtered columns with new jsonb value"
    _append: events_append_input
    "delete the field or element with specified path (for JSON arrays, negative integers count from the end)"
    _delete_at_path: events_delete_at_path_input
    "delete the array element with specified index (negative integers count from the end). throws an error if top level container is not an array"
    _delete_elem: events_delete_elem_input
    "delete key/value pair or string element. key/value pairs are matched based on their key value"
    _delete_key: events_delete_key_input
    "prepend existing jsonb value of filtered columns with new jsonb value"
    _prepend: events_prepend_input
    "sets the columns of the filtered rows to the given values"
    _set: events_set_input
    "filter the rows which have to be updated"
    where: events_bool_exp!
}

input geography_cast_exp {
    geometry: geometry_comparison_exp
}

"Boolean expression to compare columns of type \"geography\". All fields are combined with logical 'AND'."
input geography_comparison_exp {
    _cast: geography_cast_exp
    _eq: geography
    _gt: geography
    _gte: geography
    _in: [geography!]
    _is_null: Boolean
    _lt: geography
    _lte: geography
    _neq: geography
    _nin: [geography!]
    "is the column within a given distance from the given geography value"
    _st_d_within: st_d_within_geography_input
    "does the column spatially intersect the given geography value"
    _st_intersects: geography
}

input geometry_cast_exp {
    geography: geography_comparison_exp
}

"Boolean expression to compare columns of type \"geometry\". All fields are combined with logical 'AND'."
input geometry_comparison_exp {
    _cast: geometry_cast_exp
    _eq: geometry
    _gt: geometry
    _gte: geometry
    _in: [geometry!]
    _is_null: Boolean
    _lt: geometry
    _lte: geometry
    _neq: geometry
    _nin: [geometry!]
    "is the column within a given 3D distance from the given geometry value"
    _st_3d_d_within: st_d_within_input
    "does the column spatially intersect the given geometry value in 3D"
    _st_3d_intersects: geometry
    "does the column contain the given geometry value"
    _st_contains: geometry
    "does the column cross the given geometry value"
    _st_crosses: geometry
    "is the column within a given distance from the given geometry value"
    _st_d_within: st_d_within_input
    "is the column equal to given geometry value (directionality is ignored)"
    _st_equals: geometry
    "does the column spatially intersect the given geometry value"
    _st_intersects: geometry
    "does the column 'spatially overlap' (intersect but not completely contain) the given geometry value"
    _st_overlaps: geometry
    "does the column have atleast one point in common with the given geometry value"
    _st_touches: geometry
    "is the column contained in the given geometry value"
    _st_within: geometry
}

"Boolean expression to filter rows from the table \"images_hashes\". All fields are combined with a logical 'AND'."
input images_hashes_bool_exp {
    _and: [images_hashes_bool_exp!]
    _not: images_hashes_bool_exp
    _or: [images_hashes_bool_exp!]
    hash: String_comparison_exp
    image_url: String_comparison_exp
}

"input type for inserting data into table \"images_hashes\""
input images_hashes_insert_input {
    hash: String
    image_url: String
}

"input type for inserting object relation for remote table \"images_hashes\""
input images_hashes_obj_rel_insert_input {
    data: images_hashes_insert_input!
    "upsert condition"
    on_conflict: images_hashes_on_conflict
}

"on_conflict condition type for table \"images_hashes\""
input images_hashes_on_conflict {
    constraint: images_hashes_constraint!
    update_columns: [images_hashes_update_column!]! = []
    where: images_hashes_bool_exp
}

"Ordering options when selecting data from \"images_hashes\"."
input images_hashes_order_by {
    hash: order_by
    image_url: order_by
}

"primary key columns input for table: images_hashes"
input images_hashes_pk_columns_input {
    image_url: String!
}

"input type for updating data in table \"images_hashes\""
input images_hashes_set_input {
    hash: String
    image_url: String
}

"Streaming cursor of the table \"images_hashes\""
input images_hashes_stream_cursor_input {
    "Stream column input with initial value"
    initial_value: images_hashes_stream_cursor_value_input!
    "cursor ordering"
    ordering: cursor_ordering
}

"Initial value of the column from where the streaming should start"
input images_hashes_stream_cursor_value_input {
    hash: String
    image_url: String
}

input images_hashes_updates {
    "sets the columns of the filtered rows to the given values"
    _set: images_hashes_set_input
    "filter the rows which have to be updated"
    where: images_hashes_bool_exp!
}

input jsonb_cast_exp {
    String: String_comparison_exp
}

"Boolean expression to compare columns of type \"jsonb\". All fields are combined with logical 'AND'."
input jsonb_comparison_exp {
    _cast: jsonb_cast_exp
    "is the column contained in the given json value"
    _contained_in: jsonb
    "does the column contain the given json value at the top level"
    _contains: jsonb
    _eq: jsonb
    _gt: jsonb
    _gte: jsonb
    "does the string exist as a top-level key in the column"
    _has_key: String
    "do all of these strings exist as top-level keys in the column"
    _has_keys_all: [String!]
    "do any of these strings exist as top-level keys in the column"
    _has_keys_any: [String!]
    _in: [jsonb!]
    _is_null: Boolean
    _lt: jsonb
    _lte: jsonb
    _neq: jsonb
    _nin: [jsonb!]
}

input memories_aggregate_bool_exp {
    count: memories_aggregate_bool_exp_count
}

input memories_aggregate_bool_exp_count {
    arguments: [memories_select_column!]
    distinct: Boolean
    filter: memories_bool_exp
    predicate: Int_comparison_exp!
}

"order by aggregate values of table \"memories\""
input memories_aggregate_order_by {
    count: order_by
    max: memories_max_order_by
    min: memories_min_order_by
}

"input type for inserting array relation for remote table \"memories\""
input memories_arr_rel_insert_input {
    data: [memories_insert_input!]!
    "upsert condition"
    on_conflict: memories_on_conflict
}

"Boolean expression to filter rows from the table \"memories\". All fields are combined with a logical 'AND'."
input memories_bool_exp {
    _and: [memories_bool_exp!]
    _not: memories_bool_exp
    _or: [memories_bool_exp!]
    creation_time: timestamptz_comparison_exp
    creator_address: String_comparison_exp
    details_link: String_comparison_exp
    event: events_bool_exp
    event_id: String_comparison_exp
    id: String_comparison_exp
    image_hash: images_hashes_bool_exp
    image_url: String_comparison_exp
    likes: memory_likes_bool_exp
    likes_aggregate: memory_likes_aggregate_bool_exp
    likes_count: bigint_comparison_exp
}

"input type for inserting data into table \"memories\""
input memories_insert_input {
    creation_time: timestamptz
    creator_address: String
    details_link: String
    event: events_obj_rel_insert_input
    event_id: String
    id: String
    image_hash: images_hashes_obj_rel_insert_input
    image_url: String
    likes: memory_likes_arr_rel_insert_input
}

"order by max() on columns of table \"memories\""
input memories_max_order_by {
    creation_time: order_by
    creator_address: order_by
    details_link: order_by
    event_id: order_by
    id: order_by
    image_url: order_by
}

"order by min() on columns of table \"memories\""
input memories_min_order_by {
    creation_time: order_by
    creator_address: order_by
    details_link: order_by
    event_id: order_by
    id: order_by
    image_url: order_by
}

"input type for inserting object relation for remote table \"memories\""
input memories_obj_rel_insert_input {
    data: memories_insert_input!
    "upsert condition"
    on_conflict: memories_on_conflict
}

"on_conflict condition type for table \"memories\""
input memories_on_conflict {
    constraint: memories_constraint!
    update_columns: [memories_update_column!]! = []
    where: memories_bool_exp
}

"Ordering options when selecting data from \"memories\"."
input memories_order_by {
    creation_time: order_by
    creator_address: order_by
    details_link: order_by
    event: events_order_by
    event_id: order_by
    id: order_by
    image_hash: images_hashes_order_by
    image_url: order_by
    likes_aggregate: memory_likes_aggregate_order_by
    likes_count: order_by
}

"primary key columns input for table: memories"
input memories_pk_columns_input {
    id: String!
}

"input type for updating data in table \"memories\""
input memories_set_input {
    creation_time: timestamptz
    creator_address: String
    details_link: String
    event_id: String
    id: String
    image_url: String
}

"Streaming cursor of the table \"memories\""
input memories_stream_cursor_input {
    "Stream column input with initial value"
    initial_value: memories_stream_cursor_value_input!
    "cursor ordering"
    ordering: cursor_ordering
}

"Initial value of the column from where the streaming should start"
input memories_stream_cursor_value_input {
    creation_time: timestamptz
    creator_address: String
    details_link: String
    event_id: String
    id: String
    image_url: String
}

input memories_updates {
    "sets the columns of the filtered rows to the given values"
    _set: memories_set_input
    "filter the rows which have to be updated"
    where: memories_bool_exp!
}

input memory_likes_aggregate_bool_exp {
    count: memory_likes_aggregate_bool_exp_count
}

input memory_likes_aggregate_bool_exp_count {
    arguments: [memory_likes_select_column!]
    distinct: Boolean
    filter: memory_likes_bool_exp
    predicate: Int_comparison_exp!
}

"order by aggregate values of table \"memory_likes\""
input memory_likes_aggregate_order_by {
    count: order_by
    max: memory_likes_max_order_by
    min: memory_likes_min_order_by
}

"input type for inserting array relation for remote table \"memory_likes\""
input memory_likes_arr_rel_insert_input {
    data: [memory_likes_insert_input!]!
    "upsert condition"
    on_conflict: memory_likes_on_conflict
}

"Boolean expression to filter rows from the table \"memory_likes\". All fields are combined with a logical 'AND'."
input memory_likes_bool_exp {
    _and: [memory_likes_bool_exp!]
    _not: memory_likes_bool_exp
    _or: [memory_likes_bool_exp!]
    creation_time: timestamptz_comparison_exp
    liker_address: String_comparison_exp
    memory: memories_bool_exp
    memory_id: String_comparison_exp
}

"input type for inserting data into table \"memory_likes\""
input memory_likes_insert_input {
    creation_time: timestamptz
    liker_address: String
    memory: memories_obj_rel_insert_input
    memory_id: String
}

"order by max() on columns of table \"memory_likes\""
input memory_likes_max_order_by {
    creation_time: order_by
    liker_address: order_by
    memory_id: order_by
}

"order by min() on columns of table \"memory_likes\""
input memory_likes_min_order_by {
    creation_time: order_by
    liker_address: order_by
    memory_id: order_by
}

"on_conflict condition type for table \"memory_likes\""
input memory_likes_on_conflict {
    constraint: memory_likes_constraint!
    update_columns: [memory_likes_update_column!]! = []
    where: memory_likes_bool_exp
}

"Ordering options when selecting data from \"memory_likes\"."
input memory_likes_order_by {
    creation_time: order_by
    liker_address: order_by
    memory: memories_order_by
    memory_id: order_by
}

"primary key columns input for table: memory_likes"
input memory_likes_pk_columns_input {
    liker_address: String!
    memory_id: String!
}

"input type for updating data in table \"memory_likes\""
input memory_likes_set_input {
    creation_time: timestamptz
    liker_address: String
    memory_id: String
}

"Streaming cursor of the table \"memory_likes\""
input memory_likes_stream_cursor_input {
    "Stream column input with initial value"
    initial_value: memory_likes_stream_cursor_value_input!
    "cursor ordering"
    ordering: cursor_ordering
}

"Initial value of the column from where the streaming should start"
input memory_likes_stream_cursor_value_input {
    creation_time: timestamptz
    liker_address: String
    memory_id: String
}

input memory_likes_updates {
    "sets the columns of the filtered rows to the given values"
    _set: memory_likes_set_input
    "filter the rows which have to be updated"
    where: memory_likes_bool_exp!
}

"append existing jsonb value of filtered columns with new jsonb value"
input notifications_append_input {
    additional_data: jsonb
}

"Boolean expression to filter rows from the table \"notifications\". All fields are combined with a logical 'AND'."
input notifications_bool_exp {
    _and: [notifications_bool_exp!]
    _not: notifications_bool_exp
    _or: [notifications_bool_exp!]
    additional_data: jsonb_comparison_exp
    body: String_comparison_exp
    id: String_comparison_exp
    image_url: String_comparison_exp
    timestamp: timestamptz_comparison_exp
    title: String_comparison_exp
    type: String_comparison_exp
    user_address: String_comparison_exp
}

"delete the field or element with specified path (for JSON arrays, negative integers count from the end)"
input notifications_delete_at_path_input {
    additional_data: [String!]
}

"delete the array element with specified index (negative integers count from the end). throws an error if top level container is not an array"
input notifications_delete_elem_input {
    additional_data: Int
}

"delete key/value pair or string element. key/value pairs are matched based on their key value"
input notifications_delete_key_input {
    additional_data: String
}

"input type for inserting data into table \"notifications\""
input notifications_insert_input {
    additional_data: jsonb
    body: String
    id: String
    image_url: String
    timestamp: timestamptz
    title: String
    type: String
    user_address: String
}

"on_conflict condition type for table \"notifications\""
input notifications_on_conflict {
    constraint: notifications_constraint!
    update_columns: [notifications_update_column!]! = []
    where: notifications_bool_exp
}

"Ordering options when selecting data from \"notifications\"."
input notifications_order_by {
    additional_data: order_by
    body: order_by
    id: order_by
    image_url: order_by
    timestamp: order_by
    title: order_by
    type: order_by
    user_address: order_by
}

"primary key columns input for table: notifications"
input notifications_pk_columns_input {
    id: String!
}

"prepend existing jsonb value of filtered columns with new jsonb value"
input notifications_prepend_input {
    additional_data: jsonb
}

"input type for updating data in table \"notifications\""
input notifications_set_input {
    additional_data: jsonb
    body: String
    id: String
    image_url: String
    timestamp: timestamptz
    title: String
    type: String
    user_address: String
}

"Streaming cursor of the table \"notifications\""
input notifications_stream_cursor_input {
    "Stream column input with initial value"
    initial_value: notifications_stream_cursor_value_input!
    "cursor ordering"
    ordering: cursor_ordering
}

"Initial value of the column from where the streaming should start"
input notifications_stream_cursor_value_input {
    additional_data: jsonb
    body: String
    id: String
    image_url: String
    timestamp: timestamptz
    title: String
    type: String
    user_address: String
}

input notifications_updates {
    "append existing jsonb value of filtered columns with new jsonb value"
    _append: notifications_append_input
    "delete the field or element with specified path (for JSON arrays, negative integers count from the end)"
    _delete_at_path: notifications_delete_at_path_input
    "delete the array element with specified index (negative integers count from the end). throws an error if top level container is not an array"
    _delete_elem: notifications_delete_elem_input
    "delete key/value pair or string element. key/value pairs are matched based on their key value"
    _delete_key: notifications_delete_key_input
    "prepend existing jsonb value of filtered columns with new jsonb value"
    _prepend: notifications_prepend_input
    "sets the columns of the filtered rows to the given values"
    _set: notifications_set_input
    "filter the rows which have to be updated"
    where: notifications_bool_exp!
}

"Boolean expression to filter rows from the table \"profile\". All fields are combined with a logical 'AND'."
input profile_bool_exp {
    _and: [profile_bool_exp!]
    _not: profile_bool_exp
    _or: [profile_bool_exp!]
    address: String_comparison_exp
    bio: String_comparison_exp
    cover_pic: String_comparison_exp
    creation_time: timestamp_comparison_exp
    dtag: String_comparison_exp
    height: bigint_comparison_exp
    nickname: String_comparison_exp
    profile_pic: String_comparison_exp
}

"input type for incrementing numeric columns in table \"profile\""
input profile_inc_input {
    height: bigint
}

"input type for inserting data into table \"profile\""
input profile_insert_input {
    address: String
    bio: String
    cover_pic: String
    creation_time: timestamp
    dtag: String
    height: bigint
    nickname: String
    profile_pic: String
}

"on_conflict condition type for table \"profile\""
input profile_on_conflict {
    constraint: profile_constraint!
    update_columns: [profile_update_column!]! = []
    where: profile_bool_exp
}

"Ordering options when selecting data from \"profile\"."
input profile_order_by {
    address: order_by
    bio: order_by
    cover_pic: order_by
    creation_time: order_by
    dtag: order_by
    height: order_by
    nickname: order_by
    profile_pic: order_by
}

"primary key columns input for table: profile"
input profile_pk_columns_input {
    address: String!
}

"input type for updating data in table \"profile\""
input profile_set_input {
    address: String
    bio: String
    cover_pic: String
    creation_time: timestamp
    dtag: String
    height: bigint
    nickname: String
    profile_pic: String
}

"Streaming cursor of the table \"profile\""
input profile_stream_cursor_input {
    "Stream column input with initial value"
    initial_value: profile_stream_cursor_value_input!
    "cursor ordering"
    ordering: cursor_ordering
}

"Initial value of the column from where the streaming should start"
input profile_stream_cursor_value_input {
    address: String
    bio: String
    cover_pic: String
    creation_time: timestamp
    dtag: String
    height: bigint
    nickname: String
    profile_pic: String
}

input profile_updates {
    "increments the numeric columns with given value of the filtered values"
    _inc: profile_inc_input
    "sets the columns of the filtered rows to the given values"
    _set: profile_set_input
    "filter the rows which have to be updated"
    where: profile_bool_exp!
}

input st_d_within_geography_input {
    distance: Float!
    from: geography!
    use_spheroid: Boolean = true
}

input st_d_within_input {
    distance: Float!
    from: geometry!
}

"Boolean expression to compare columns of type \"timestamp\". All fields are combined with logical 'AND'."
input timestamp_comparison_exp {
    _eq: timestamp
    _gt: timestamp
    _gte: timestamp
    _in: [timestamp!]
    _is_null: Boolean
    _lt: timestamp
    _lte: timestamp
    _neq: timestamp
    _nin: [timestamp!]
}

"Boolean expression to compare columns of type \"timestamptz\". All fields are combined with logical 'AND'."
input timestamptz_comparison_exp {
    _eq: timestamptz
    _gt: timestamptz
    _gte: timestamptz
    _in: [timestamptz!]
    _is_null: Boolean
    _lt: timestamptz
    _lte: timestamptz
    _neq: timestamptz
    _nin: [timestamptz!]
}

"Boolean expression to filter rows from the table \"user_contacts\". All fields are combined with a logical 'AND'."
input user_contacts_bool_exp {
    _and: [user_contacts_bool_exp!]
    _not: user_contacts_bool_exp
    _or: [user_contacts_bool_exp!]
    creation_time: timestamptz_comparison_exp
    desmos_address: String_comparison_exp
    id: String_comparison_exp
    platform: String_comparison_exp
    shared_contacts: bond_shared_contacts_bool_exp
    shared_contacts_aggregate: bond_shared_contacts_aggregate_bool_exp
    username: String_comparison_exp
}

"input type for inserting data into table \"user_contacts\""
input user_contacts_insert_input {
    creation_time: timestamptz
    desmos_address: String
    id: String
    platform: String
    shared_contacts: bond_shared_contacts_arr_rel_insert_input
    username: String
}

"input type for inserting object relation for remote table \"user_contacts\""
input user_contacts_obj_rel_insert_input {
    data: user_contacts_insert_input!
    "upsert condition"
    on_conflict: user_contacts_on_conflict
}

"on_conflict condition type for table \"user_contacts\""
input user_contacts_on_conflict {
    constraint: user_contacts_constraint!
    update_columns: [user_contacts_update_column!]! = []
    where: user_contacts_bool_exp
}

"Ordering options when selecting data from \"user_contacts\"."
input user_contacts_order_by {
    creation_time: order_by
    desmos_address: order_by
    id: order_by
    platform: order_by
    shared_contacts_aggregate: bond_shared_contacts_aggregate_order_by
    username: order_by
}

"primary key columns input for table: user_contacts"
input user_contacts_pk_columns_input {
    id: String!
}

"input type for updating data in table \"user_contacts\""
input user_contacts_set_input {
    creation_time: timestamptz
    desmos_address: String
    id: String
    platform: String
    username: String
}

"Streaming cursor of the table \"user_contacts\""
input user_contacts_stream_cursor_input {
    "Stream column input with initial value"
    initial_value: user_contacts_stream_cursor_value_input!
    "cursor ordering"
    ordering: cursor_ordering
}

"Initial value of the column from where the streaming should start"
input user_contacts_stream_cursor_value_input {
    creation_time: timestamptz
    desmos_address: String
    id: String
    platform: String
    username: String
}

input user_contacts_updates {
    "sets the columns of the filtered rows to the given values"
    _set: user_contacts_set_input
    "filter the rows which have to be updated"
    where: user_contacts_bool_exp!
}
